{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PianoRollConvEncoder(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(1, 2, kernel_size=(10, 10), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(2, 4, kernel_size=(6, 6), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "  )\n",
      "  (fc): Linear(in_features=20768, out_features=64, bias=True)\n",
      ")\n",
      "ProjectionHead(\n",
      "  (projector): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n",
      "SiameseModel(\n",
      "  (encoder): PianoRollConvEncoder(\n",
      "    (conv_layers): Sequential(\n",
      "      (0): Conv2d(1, 2, kernel_size=(10, 10), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(2, 4, kernel_size=(6, 6), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU()\n",
      "    )\n",
      "    (fc): Linear(in_features=20768, out_features=64, bias=True)\n",
      "  )\n",
      "  (projection_head): ProjectionHead(\n",
      "    (projector): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "os.chdir(\"c:/Users/cunn2/OneDrive/DSML/Project/thesis-repo\")\n",
    "\n",
    "from sms.exp1.config_classes import load_config_from_launchplan\n",
    "from sms.exp1.run_training import build_encoder, build_projector\n",
    "from sms.exp1.models.siamese import SiameseModel\n",
    "\n",
    "config = load_config_from_launchplan(\"sms/exp1/runs/run_20240926_162652/original_launchplan.yaml\")\n",
    "\n",
    "encoder = build_encoder(config.model_dump())\n",
    "projector = build_projector(config.model_dump())\n",
    "\n",
    "model = SiameseModel(encoder, projector)\n",
    "\n",
    "print(encoder)\n",
    "print(projector)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cunn2\\AppData\\Local\\Temp\\ipykernel_181064\\885777492.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pt_encoder.load_state_dict(torch.load(\"sms/exp1/runs/run_20240926_162652/pretrain_saved_model.pth\"))\n",
      "C:\\Users\\cunn2\\AppData\\Local\\Temp\\ipykernel_181064\\885777492.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ft_encoder.load_state_dict(torch.load(\"sms/exp1/runs/run_20240926_162652/finetune_saved_model.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_encoder = build_encoder(config.model_dump())\n",
    "pt_encoder.load_state_dict(torch.load(\"sms/exp1/runs/run_20240926_162652/pretrain_saved_model.pth\"))    \n",
    "\n",
    "ft_encoder = build_encoder(config.model_dump())\n",
    "ft_encoder.load_state_dict(torch.load(\"sms/exp1/runs/run_20240926_162652/finetune_saved_model.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cunn2\\AppData\\Local\\Temp\\ipykernel_181064\\1356997116.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(r\"C:\\Users\\cunn2\\OneDrive\\DSML\\Project\\thesis-repo\\data\\exp1\\train_data.pt\")\n"
     ]
    }
   ],
   "source": [
    "data = torch.load(r\"C:\\Users\\cunn2\\OneDrive\\DSML\\Project\\thesis-repo\\data\\exp1\\train_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2, 67. ],\n",
       "       [ 1. , 74. ],\n",
       "       [ 2. , 76. ],\n",
       "       [ 0.8, 74. ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-09-29 15:12:42] [DEBUG] Transposing non-rest notes by 5 semitones.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2 67. ]\n",
      " [ 1.  74. ]\n",
      " [ 2.  76. ]\n",
      " [ 0.8 74. ]]\n",
      "tensor([[ 0.2000, 72.0000],\n",
      "        [ 1.0000, 79.0000],\n",
      "        [ 2.0000, 81.0000],\n",
      "        [ 0.8000, 79.0000]], dtype=torch.float64)\n",
      "[[ 0.75 67.  ]\n",
      " [ 0.25 69.  ]\n",
      " [ 1.   71.  ]\n",
      " [ 0.5  67.  ]\n",
      " [ 0.5  67.  ]\n",
      " [ 1.   69.  ]]\n",
      "pos distance: 22.374937057495117\n",
      "neg distance: 20.81243324279785\n"
     ]
    }
   ],
   "source": [
    "from sms.src.synthetic_data.formatter import InputFormatter\n",
    "from sms.src.synthetic_data.note_arr_mod import NoteArrayModifier\n",
    "import numpy as np\n",
    "import logging\n",
    "from sms.src.log import configure_logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "configure_logging(console_level=logging.DEBUG)\n",
    "\n",
    "formatter = InputFormatter(**config.model_dump()['input'])\n",
    "\n",
    "aug_dict = {\n",
    "    \"use_transposition\": True,\n",
    "    \"use_shift_selected_notes_pitch\": False,\n",
    "    \"use_change_note_durations\": False,\n",
    "    \"use_delete_notes\": False,\n",
    "    \"use_insert_notes\": False\n",
    "}\n",
    "\n",
    "modifier = NoteArrayModifier()\n",
    "\n",
    "def format_data(data: np.ndarray):\n",
    "    return formatter(data).astype(np.float32).copy()\n",
    "\n",
    "anchor = data[0]\n",
    "pos = modifier(anchor, aug_dict)\n",
    "neg = data[18]\n",
    "print(anchor)\n",
    "print(pos)\n",
    "print(neg)\n",
    "\n",
    "anchor = format_data(anchor)\n",
    "pos = format_data(pos)\n",
    "neg = format_data(data[17])\n",
    "\n",
    "anchor_enc = ft_encoder((torch.from_numpy(anchor)).unsqueeze(0))[0].detach().numpy()   \n",
    "pos_enc = ft_encoder((torch.from_numpy(pos)).unsqueeze(0))[0].detach().numpy()\n",
    "neg_enc = ft_encoder((torch.from_numpy(neg)).unsqueeze(0))[0].detach().numpy()\n",
    "\n",
    "print(f'pos distance: {np.linalg.norm(anchor_enc - pos_enc)}')\n",
    "print(f'neg distance: {np.linalg.norm(anchor_enc - neg_enc)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def format_data_for_conv_enc(data: np.ndarray, formatter: InputFormatter):\n",
    "    return torch.from_numpy(formatter(data).astype(np.float32).copy())\n",
    "\n",
    "def format_dataset_for_conv_enc(dataset: List[np.ndarray]):\n",
    "    formatted_data = [format_data_for_conv_enc(data, formatter) for data in dataset]\n",
    "    return torch.stack(formatted_data, dim=0)\n",
    "\n",
    "data_formatted = format_dataset_for_conv_enc(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14631, 128, 32])\n"
     ]
    }
   ],
   "source": [
    "print(data_formatted.shape)\n",
    "embeddings = ft_encoder(data_formatted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14631, 64])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.8189e+00, -1.0568e+01,  1.3061e+00, -3.7155e+00,  2.3748e+00,\n",
       "        -9.1931e+00,  4.0135e+00,  7.2098e+00,  1.6388e+00,  1.6952e+01,\n",
       "         3.5173e+00, -3.6373e+00,  3.9732e+00,  1.5120e+01,  1.0261e+00,\n",
       "         1.1293e+01,  6.1510e+00, -4.7417e+00, -4.8012e+00, -1.4328e+01,\n",
       "        -2.8075e+00, -3.0592e+00, -7.0917e+00, -7.3687e+00,  1.3666e+00,\n",
       "        -2.9715e+00,  4.9831e+00,  5.1463e+00, -3.3394e+00, -6.1344e+00,\n",
       "        -6.1643e+00, -1.6928e+01, -2.0705e+00,  7.5320e-01, -7.7485e+00,\n",
       "        -9.8449e+00,  4.6780e+00,  3.3799e+00,  4.8790e+00, -1.0553e-02,\n",
       "         2.3219e+00,  1.0051e+01, -8.1662e+00,  1.1222e+01,  1.2169e+00,\n",
       "         2.3066e+00, -1.3469e+01,  4.2552e-01, -3.1998e+00, -1.3172e+00,\n",
       "        -1.8167e+00,  6.6501e+00,  8.4608e-01,  1.6913e+00, -3.8155e+00,\n",
       "        -4.9456e+00, -9.2409e+00,  9.4063e+00,  9.8553e+00,  3.5024e+00,\n",
       "        -1.2613e+01, -2.1675e+01, -5.5904e+00, -1.0875e+00])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from typing import Dict, Any\n",
    "\n",
    "class CustomFAISSIndex:\n",
    "    def __init__(self, index_type: str, index_args: List[Any] = [], index_kwargs: Dict[str, Any] = {}):\n",
    "        self.index = getattr(faiss, index_type)(*index_args, **index_kwargs)\n",
    "        self.id_to_index = {}  # Maps custom IDs to FAISS indices\n",
    "        self.index_to_id = {}  # Maps FAISS indices to custom IDs\n",
    "        self.id_to_data = {}   # Maps custom IDs to original data\n",
    "\n",
    "    def add_with_id(self, id, vector, original_data=None):\n",
    "        if id in self.id_to_index:\n",
    "            raise ValueError(f\"ID {id} already exists in the index\")\n",
    "        \n",
    "        index = self.index.ntotal\n",
    "        self.index.add(np.array([vector], dtype=np.float32))\n",
    "        self.id_to_index[id] = index\n",
    "        self.index_to_id[index] = id\n",
    "        if original_data is not None:\n",
    "            self.id_to_data[id] = original_data\n",
    "\n",
    "    def remove(self, id):\n",
    "        if id not in self.id_to_index:\n",
    "            raise ValueError(f\"ID {id} not found in the index\")\n",
    "        \n",
    "        index_to_remove = self.id_to_index[id]\n",
    "        self.index.remove_ids(np.array([index_to_remove]))\n",
    "        \n",
    "        # Update mappings\n",
    "        del self.index_to_id[index_to_remove]\n",
    "        del self.id_to_index[id]\n",
    "        if id in self.id_to_data:\n",
    "            del self.id_to_data[id]\n",
    "        \n",
    "        # # Update remaining indices\n",
    "        # for i in range(index_to_remove, self.index.ntotal):\n",
    "        #     old_id = self.index_to_id[i + 1]\n",
    "        #     self.index_to_id[i] = old_id\n",
    "        #     self.id_to_index[old_id] = i\n",
    "        # del self.index_to_id[self.index.ntotal]\n",
    "\n",
    "        # Update remaining indices\n",
    "        for i in range(index_to_remove, self.index.ntotal):\n",
    "            if i + 1 in self.index_to_id:\n",
    "                old_id = self.index_to_id[i + 1]\n",
    "                self.index_to_id[i] = old_id\n",
    "                self.id_to_index[old_id] = i\n",
    "        \n",
    "        # Remove the last entry if it exists\n",
    "        if self.index.ntotal in self.index_to_id:\n",
    "            del self.index_to_id[self.index.ntotal]\n",
    "\n",
    "    def search(self, query_vector, k,):\n",
    "        distances, indices = self.index.search(np.array([query_vector], dtype=np.float32), k)\n",
    "        results = []\n",
    "        for idx in indices[0]:\n",
    "            if idx != -1 and idx in self.index_to_id:\n",
    "                id = self.index_to_id[idx]\n",
    "                results.append((id, self.id_to_data.get(id)))\n",
    "        return results\n",
    "\n",
    "    def get_vector(self, id):\n",
    "        if id not in self.id_to_index:\n",
    "            raise ValueError(f\"ID {id} not found in the index\")\n",
    "        index = self.id_to_index[id]\n",
    "        return self.index.reconstruct(index)\n",
    "\n",
    "    def get_original_data(self, id):\n",
    "        return self.id_to_data.get(id)\n",
    "    \n",
    "    def get_all_items(self, limit=3):\n",
    "        items = []\n",
    "        for id in list(self.id_to_data.keys())[:limit]:  # Limit the number of items\n",
    "            vector = self.get_vector(id)\n",
    "            original_data = self.get_original_data(id)\n",
    "            items.append((id, vector, original_data))\n",
    "        return items\n",
    "\n",
    "    def __repr__(self):\n",
    "        items = self.get_all_items(limit=3)  # Limit to 3 items\n",
    "        total_items = self.index.ntotal\n",
    "        repr_str = f\"CustomFAISSIndex with {total_items} items:\\n\"\n",
    "        for id, vector, original_data in items:\n",
    "            repr_str += f\"  ID: {id}\\n\"\n",
    "            repr_str += f\"    Vector: {vector}\\n\"\n",
    "            repr_str += f\"    Original Data: {original_data}\\n\"\n",
    "        if total_items > 3:\n",
    "            repr_str += f\"  ... and {total_items - 3} more items\\n\"\n",
    "        return repr_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test: Add 5 items, add a sixth, then remove the sixth\n",
    "\n",
    "import numpy as np\n",
    "from uuid import uuid4\n",
    "\n",
    "# Create a test index\n",
    "test_index = CustomFAISSIndex(index_type=\"IndexLSH\", index_args=[64, 256])\n",
    "\n",
    "# Generate 5 random items\n",
    "for _ in range(5):\n",
    "    item_id = str(uuid4())\n",
    "    vector = np.random.rand(64).astype(np.float32)\n",
    "    data = f\"Test data for {item_id}\"\n",
    "    test_index.add_with_id(item_id, vector, data)\n",
    "\n",
    "# Verify 5 items are in the index\n",
    "assert test_index.index.ntotal == 5, f\"Expected 5 items, but found {test_index.index.ntotal}\"\n",
    "\n",
    "# Add a sixth item\n",
    "sixth_id = str(uuid4())\n",
    "sixth_vector = np.random.rand(64).astype(np.float32)\n",
    "sixth_data = \"Sixth item data\"\n",
    "test_index.add_with_id(sixth_id, sixth_vector, sixth_data)\n",
    "\n",
    "# Verify 6 items are in the index\n",
    "assert test_index.index.ntotal == 6, f\"Expected 6 items, but found {test_index.index.ntotal}\"\n",
    "\n",
    "# Remove the sixth item\n",
    "test_index.remove(sixth_id)\n",
    "\n",
    "# Verify back to 5 items in the index\n",
    "assert test_index.index.ntotal == 5, f\"Expected 5 items after removal, but found {test_index.index.ntotal}\"\n",
    "\n",
    "# Try to access the removed item (should raise an error)\n",
    "try:\n",
    "    test_index.get_vector(sixth_id)\n",
    "    raise AssertionError(\"Expected ValueError when accessing removed item\")\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "print(\"All tests passed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "data_ids = [str(uuid4()) for _ in range(len(data))]\n",
    "data_dict = dict(zip(data_ids, data))\n",
    "embeddings_dict = dict(zip(data_ids, embeddings.detach().numpy()))\n",
    "\n",
    "dim = list(embeddings_dict.values())[0].shape[0]\n",
    "embedding_index = CustomFAISSIndex(index_type=\"IndexLSH\", index_args=[dim, 256])\n",
    "for key, value in embeddings_dict.items():\n",
    "    embedding_index.add_with_id(key, value, data_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2, 67. ],\n",
       "       [ 1. , 74. ],\n",
       "       [ 2. , 76. ],\n",
       "       [ 0.8, 74. ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_index.get_original_data(data_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check 1: Verify all documents are added\n",
    "# print(\"Check 1: Verify all documents are added\")\n",
    "# for doc_id in [\"doc1\", \"doc2\", \"doc3\"]:\n",
    "#     vector = embedding_index.get_vector(doc_id)\n",
    "#     data = embedding_index.get_original_data(doc_id)\n",
    "#     print(f\"{doc_id}: Vector = {vector}, Data = {data}\")\n",
    "\n",
    "# # Check 2: Remove a document and verify it's gone\n",
    "# print(\"\\nCheck 2: Remove a document and verify it's gone\")\n",
    "# embedding_index.remove(\"doc2\")\n",
    "# try:\n",
    "#     embedding_index.get_vector(\"doc2\")\n",
    "# except ValueError as e:\n",
    "#     print(f\"Expected error: {e}\")\n",
    "\n",
    "# # Check 3: Verify remaining documents are still accessible\n",
    "# print(\"\\nCheck 3: Verify remaining documents are still accessible\")\n",
    "# for doc_id in [\"doc1\", \"doc3\"]:\n",
    "#     vector = embedding_index.get_vector(doc_id)\n",
    "#     data = embedding_index.get_original_data(doc_id)\n",
    "#     print(f\"{doc_id}: Vector = {vector}, Data = {data}\")\n",
    "\n",
    "# # Check 4: Add a new document and verify it's added correctly\n",
    "# print(\"\\nCheck 4: Add a new document and verify it's added correctly\")\n",
    "# embedding_index.add_with_id(\"doc4\", np.array([4] * dim), 4)\n",
    "# embedding_index.add_with_id(\"doc5\", np.array([5] * dim), 5)\n",
    "# vector = embedding_index.get_vector(\"doc4\")\n",
    "# data = embedding_index.get_original_data(\"doc4\")\n",
    "# print(f\"doc4: Vector = {vector}, Data = {data}\")\n",
    "\n",
    "# # Check 5: Perform a search and verify results\n",
    "# print(\"\\nCheck 5: Perform a search and verify results\")\n",
    "# query_vector = np.array([2.5] * dim)\n",
    "# results = embedding_index.search(query_vector, k=2)\n",
    "# print(f\"Search results for query {query_vector}:\")\n",
    "# for id, data in results:\n",
    "#     print(f\"ID: {id}, Data: {data}\")\n",
    "\n",
    "# # Check 6: Try to add a document with an existing ID (should raise an error)\n",
    "# print(\"\\nCheck 6: Try to add a document with an existing ID\")\n",
    "# try:\n",
    "#     embedding_index.add_with_id(\"doc1\", np.array([5] * dim), 5)\n",
    "# except ValueError as e:\n",
    "#     print(f\"Expected error: {e}\")\n",
    "\n",
    "# # Check 7: Try to remove a non-existent document (should raise an error)\n",
    "# print(\"\\nCheck 7: Try to remove a non-existent document\")\n",
    "# try:\n",
    "#     embedding_index.remove(\"doc5\")\n",
    "# except ValueError as e:\n",
    "#     print(f\"Expected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp1 eval loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce vector embeddings\n",
    "from uuid import uuid4\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "from typing import Callable, Optional, List, Dict\n",
    "from sms.src.synthetic_data.formatter import InputFormatter\n",
    "from sms.src.synthetic_data.note_arr_mod import NoteArrayModifier\n",
    "\n",
    "from sms.exp1.run_training import build_encoder, build_projector\n",
    "from sms.exp1.models.siamese import SiameseModel\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def augment_chunk(chunk: np.ndarray, augmentation: str):\n",
    "    \"\"\" \n",
    "    augmentation is one of the following:\n",
    "        use_transposition\n",
    "        use_shift_selected_notes_pitch\n",
    "        use_change_note_durations\n",
    "        use_delete_notes\n",
    "        use_insert_notes\n",
    "    \"\"\"\n",
    "    aug_dict = {\n",
    "        \"use_transposition\": False,\n",
    "        \"use_shift_selected_notes_pitch\": False,\n",
    "        \"use_change_note_durations\": False,\n",
    "        \"use_delete_notes\": False,\n",
    "        \"use_insert_notes\": False\n",
    "    }\n",
    "    aug_dict[augmentation] = True\n",
    "    modifier = NoteArrayModifier()\n",
    "    return modifier(chunk, aug_dict)\n",
    "\n",
    "def create_augmented_data(data_dict: Dict[str, np.ndarray], anchor_keys: List[str]) -> Dict[str, Dict[str, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Create the augmented data for the given anchor keys.\n",
    "    Returns a dictionary of dictionaries, where the outer dictionary is keyed by the anchor keys, and the inner dictionary \n",
    "        is keyed by the type of augmentation and contains the augmented data.\n",
    "    \"\"\"\n",
    "    augmented_data = {}\n",
    "    for key in anchor_keys:\n",
    "        chunk = data_dict[key]\n",
    "        augmented_data[key] = {\n",
    "            \"chunk_transposed\": augment_chunk(chunk, \"use_transposition\"),\n",
    "            \"chunk_one_pitch_shifted\": augment_chunk(chunk, \"use_shift_selected_notes_pitch\"),\n",
    "            \"chunk_note_duration_changed\": augment_chunk(chunk, \"use_change_note_durations\"),\n",
    "            \"chunk_note_deleted\": augment_chunk(chunk, \"use_delete_notes\"),\n",
    "            \"chunk_note_inserted\": augment_chunk(chunk, \"use_insert_notes\")\n",
    "        }\n",
    "    return augmented_data\n",
    "\n",
    "def build_model(dumped_lp_config: Dict[str, Any], full_model_path: Optional[str] = None, encoder_path: Optional[str] = None, use_full_model: bool = False):\n",
    "    \"\"\"\n",
    "    Only one of full_model_path or encoder_path should be provided. If both are provided, full_model_path is used.\n",
    "    \"\"\"\n",
    "    encoder = build_encoder(dumped_lp_config)\n",
    "    projector = build_projector(dumped_lp_config)\n",
    "    model = SiameseModel(encoder, projector)\n",
    "    if full_model_path is not None:\n",
    "        model.load_state_dict(torch.load(full_model_path))\n",
    "    elif encoder_path is not None:\n",
    "        model = model.get_encoder()\n",
    "        model.load_state_dict(torch.load(encoder_path))\n",
    "    else:\n",
    "        raise ValueError(\"Either full_model_path or encoder_path must be provided.\")\n",
    "    if not use_full_model and full_model_path is not None:\n",
    "        model = model.get_encoder()\n",
    "    return model\n",
    "\n",
    "def create_embedding_dict(data_dict: Dict[str, np.ndarray], dumped_lp_config: Dict[str, Any], model: Callable) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Create the embedding dictionary for the given model. The dumped_lp_config is used to determine the input format of the model.\n",
    "    Returns the data_dict, but with embeddings instead of the original data.\n",
    "    \"\"\"\n",
    "    formatter = InputFormatter(**dumped_lp_config['input'])\n",
    "    formatted_data_list = [torch.from_numpy(formatter(chunk).astype(np.float32).copy()) for chunk in data_dict.values()]\n",
    "    formatted_data_stacked = torch.stack(formatted_data_list, dim=0) # shape [num_chunks, *input_shape]\n",
    "    embeddings_stacked = model(formatted_data_stacked)\n",
    "    embeddings_dict = {key: embeddings_stacked[i].detach().numpy() for i, key in enumerate(data_dict.keys())}\n",
    "    return embeddings_dict\n",
    "\n",
    "def embeddings_to_faiss_index(\n",
    "        embeddings_dict: Dict[str, np.ndarray], \n",
    "        index_type: str, \n",
    "        index_args: List[Any] = [], \n",
    "        index_kwargs: Dict[str, Any] = {}\n",
    "    ) -> CustomFAISSIndex:\n",
    "\n",
    "    embedding_index = CustomFAISSIndex(index_type=index_type, index_args=index_args, index_kwargs=index_kwargs)\n",
    "    for key, value in embeddings_dict.items():\n",
    "        embedding_index.add_with_id(key, value)\n",
    "    return embedding_index\n",
    "\n",
    "    # For each embedding collection in embeddings_dicts, we perform the augmentation evaluation experiment num_loops times.\n",
    "    # An augmentation evaluation experiment involves the following steps:\n",
    "    # - Randomly select an anchor from data_dict\n",
    "    # - Remove the anchor from data_dict\n",
    "    # - Apply each of the five given augmentations to the anchor\n",
    "    # - For each of the augmented melodies, add it to the database and perform a nearest neighbor search on the FAISS index\n",
    "    # - Calculate the precision and recall of the search for each k in k_list\n",
    "\n",
    "def evaluate_top_k(\n",
    "        embedding_dict: Dict[str, Dict[str, np.ndarray]],\n",
    "        augmented_embedding_dict: Dict[str, Dict[str, np.ndarray]], \n",
    "        k_list: List[int], \n",
    "        index: CustomFAISSIndex\n",
    "    ) -> Dict[str, Dict[str, Dict[str, List[float]]]]:\n",
    "    \"\"\"\n",
    "    index is a CustomFAISSIndex object which has been initialized with the embeddings_dict.\n",
    "    For each of the keys in augment_dict, we perform the following steps:\n",
    "    - Remove the anchor (embedding_dict[key]) from the index\n",
    "    - Add one of the augmentations from that key to the index\n",
    "    - Perform a nearest neighbor search on the index using the anchor and record the position of the augmentation\n",
    "    - Repeat for each augmentation\n",
    "    \n",
    "    Then we report the average precision and recall for each k in k_list.\n",
    "    \n",
    "    Args:\n",
    "        embeddings_dict: dictionary of embeddings, keyed by data ids\n",
    "        augmented_embedding_dict: dictionary keyed by a subset of the ids in embeddings_dict, containing dictionaries of augmented data\n",
    "        k_list: list of k values to evaluate\n",
    "        index: CustomFAISSIndex object which has been initialized with the embeddings_dict\n",
    "\n",
    "    Returns:\n",
    "        results: dictionary of precision and recall for each augmentation and k in k_list\n",
    "    \"\"\"\n",
    "    results = {aug_type: {k: {'precision': [], 'recall': []} for k in k_list} for aug_type in augmented_embedding_dict[list(augmented_embedding_dict.keys())[0]].keys()}\n",
    "    \n",
    "    for anchor_id, augmentations in augmented_embedding_dict.items():\n",
    "        anchor_embedding = embedding_dict[anchor_id]\n",
    "        \n",
    "        # remove anchor from index\n",
    "        index.remove(anchor_id)\n",
    "        \n",
    "        for aug_type, augmented_data in augmentations.items():\n",
    "            # add augmented data to index\n",
    "            aug_id = f\"{anchor_id}_aug_{aug_type}\"\n",
    "            index.add_with_id(aug_id, augmented_data)\n",
    "            \n",
    "            # perform search\n",
    "            search_results = index.search(anchor_embedding, max(k_list))\n",
    "            \n",
    "            # calculate precision and recall for each k\n",
    "            for k in k_list:\n",
    "                top_k_results = search_results[:k]\n",
    "                true_positives = sum(1 for id, _ in top_k_results if id == aug_id)\n",
    "                \n",
    "                precision = true_positives / k\n",
    "                recall = 1 if true_positives > 0 else 0  # Recall is 1 if found, 0 if not\n",
    "                \n",
    "                results[aug_type][k]['precision'].append(precision)\n",
    "                results[aug_type][k]['recall'].append(recall)\n",
    "            \n",
    "            # remove augmented data from index\n",
    "            index.remove(aug_id)\n",
    "        \n",
    "        # add anchor back to index\n",
    "        index.add_with_id(anchor_id, anchor_embedding)\n",
    "    \n",
    "    # Calculate average precision and recall\n",
    "    for aug_type in results:\n",
    "        for k in k_list:\n",
    "            results[aug_type][k]['avg_precision'] = np.mean(results[aug_type][k]['precision'])\n",
    "            results[aug_type][k]['avg_recall'] = np.mean(results[aug_type][k]['recall'])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 1 by -3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.2999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.4 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 0.5 and relative pitch -4.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 14 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 6 by 1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 1 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 7 with duration 0.65 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 5 with duration 0.125 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 4 with duration 0.375 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 3 with duration 0.125 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 2 by 0.2250000000000001 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [7].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.6499999999999999 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 6 with duration 0.25 and relative pitch 0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 8 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -12 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by -4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 4 with duration 0.6 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 1.4 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 1 with duration 0.5 and relative pitch 5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 11 by -6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 11 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 13 with duration 0.325 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 12 by 0.175 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [11].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 11 with duration 0.25 and relative pitch -5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 14 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 2 by 4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.09999999999999964 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.2999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 1.0 and relative pitch 1.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 4 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.7 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -12 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by 2 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 2 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 4 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 3 with duration 1.0 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 2 by 0.8 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 4 with duration 0.25 and relative pitch 4.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 5 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.04999999999999999 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 11 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by 0 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.3999999999999999 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 3 with duration 0.5 and relative pitch -2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 5 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 8 by -7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 2.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 9 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 8 with duration 0.5 and relative pitch -1.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 10 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 9 by 0.2 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 1 by 3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 2 with duration 0.6 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 1 with duration 1.0 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 0 by 3.1999999999999993 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 1.0 and relative pitch -5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 3 with duration 0.6 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 2 by 0.4 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -11 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 4 by -7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 1 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 0.5 and relative pitch 3.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 5 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 11 by 0 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 7 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.125 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [8].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 8 with duration 0.25 and relative pitch 1.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 16 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by -6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 4 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.15000000000000036 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 0.25 and relative pitch -1.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 8 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 4 by 0 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 4 with duration 0.6 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.19999999999999984 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.6000000000000001 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 3 with duration 1.0 and relative pitch -5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 5 with duration 0.6 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.4 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 14 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 2 by -4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 1 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 0.5 and relative pitch 0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 1 by 6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 5 by a factor of 2.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 10 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 9 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 8 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 7 by 0.15000000000000002 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [9].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 6 with duration 0.25 and relative pitch -6.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 11 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 10 by 0.15 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 15 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by -1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 3 with duration 0.5 and relative pitch 5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -10 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 4 by -4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 2 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 4 with duration 1.0 and relative pitch -2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 5 with duration 1.0 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 15 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by -3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 4 with duration 0.6 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.19999999999999984 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 0.25 and relative pitch 5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 2 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by 2 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 5 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.19999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 0.5 and relative pitch 0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 7 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 0.2 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 8 by 6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 2.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 8 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 7 by 0.2 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 7 with duration 1.0 and relative pitch 0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 9 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 8 by 0.7 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by 6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 7 with duration 0.05 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 5 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 4 with duration 1.0 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.19999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 4 with duration 0.5 and relative pitch 0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 8 with duration 0.05 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 7 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 0.2 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 2 by -1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 1 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 5 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 4 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.275 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.3999999999999999 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 5 with duration 0.25 and relative pitch 2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.15 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by 2 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 4 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [7].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 1 with duration 1.0 and relative pitch 3.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 10 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 9 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 8 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 7 by 0.15000000000000002 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -14 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 2 by -6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.5999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 1 with duration 1.0 and relative pitch 5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 5 with duration 0.8 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.19999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 10 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 1 by -8 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 1 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 1.0 and relative pitch 2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 1 by -4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 1 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 5 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 4 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.8 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 1 with duration 0.25 and relative pitch -3.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.04999999999999999 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 6 by 7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 6 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 0.5999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [6].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.2999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 0.25 and relative pitch 5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 7 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -14 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 7 by 2 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 7 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 7 by 0.8000000000000007 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 5 with duration 1.0 and relative pitch 5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 8 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 7 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -14 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by -7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 5 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.20000000000000018 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [5].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.10000000000000009 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 1 with duration 0.25 and relative pitch 1.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.15 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 2 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by 4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 2 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 3 with duration 0.5 and relative pitch 0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 0 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 1 by -4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 3 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 2 by 1.4000000000000006 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.20000000000000018 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 3 with duration 0.5 and relative pitch -1.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 4 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.3 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 0 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by 1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 7 by a factor of 2.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 8 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [6].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 1.0 and relative pitch 0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 9 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 8 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 7 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 0.19999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 8 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 6 by -5 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 7 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 0.10000000000000037 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [5].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 1 with duration 1.0 and relative pitch 4.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 8 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 7 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 0.19999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by 5 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 4 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 5 with duration 0.25 and relative pitch 3.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 12 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 7 by 2 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.125 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [5].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 1 with duration 1.0 and relative pitch -3.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 11 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 10 by 0.7 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -5 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 1 by -7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 7 with duration 1.0 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 1 with duration 1.0 and relative pitch 0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 8 with duration 1.0 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 1 by -6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 2 by a factor of 2.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.7999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 3 with duration 0.25 and relative pitch -4.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -8 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 1 by -3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 2 by a factor of 2.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 2 by 1.8000000000000007 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.7999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 0.5 and relative pitch 5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by -6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 4 with duration 0.5 and relative pitch -6.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 11 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by 3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 5 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 11 with duration 0.15 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 10 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 9 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 8 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 7 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 3 with duration 0.5 and relative pitch 2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 12 with duration 0.15 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 11 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 10 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by -8 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 2 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 3 with duration 0.5 and relative pitch 3.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -2 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by -7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 2 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 3 with duration 0.5 and relative pitch -2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 15 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by 5 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 2 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.2999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 5 with duration 1.0 and relative pitch -2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.7 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.30000000000000004 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -5 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 2 by 0 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 2 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 3 with duration 0.25 and relative pitch -6.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 5 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by -5 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.30000000000000027 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.3999999999999999 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 4 with duration 1.0 and relative pitch -5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 5 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.6 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 8 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 2 by 4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.09999999999999964 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.20000000000000018 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 1 with duration 0.5 and relative pitch -1.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 5 by -7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 9 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.02499999999999991 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [7].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 0.5 and relative pitch 1.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 10 with duration 0.05 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 9 by 0.45 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 5 by -8 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 11 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 11 by 0.40000000000000036 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 1.0 and relative pitch -2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 12 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 11 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 10 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 9 by 0.050000000000000044 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 11 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 4 by -4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 6 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 9 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 8 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 7 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 2.2 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 8 with duration 0.5 and relative pitch 1.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 10 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 9 by 0.2 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 13 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 2 by 3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 2 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 5 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.7 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 3 with duration 0.25 and relative pitch -2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 2 by -3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 1 by a factor of 2.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 2 by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.2000000000000002 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 0.25 and relative pitch -1.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -2 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by -6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 2.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 5 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 4 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.6000000000000001 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 0.5 and relative pitch 4.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -12 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by -3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.75 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 0.25 and relative pitch -1.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -13 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by 5 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 1 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 2 with duration 0.8 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 1 by 0.7 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.20000000000000018 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 1 with duration 1.0 and relative pitch 2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 3 with duration 0.8 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 2 by 0.19999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by -8 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 2.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 1 with duration 1.0 and relative pitch 4.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 4 with duration 1.0 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by 4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 5 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.6000000000000001 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 5 with duration 1.0 and relative pitch 1.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 7 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 0.6 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 12 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by 3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 2 with duration 1.2 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 1 with duration 1.0 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 0 by 1.4000000000000004 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 1 with duration 1.0 and relative pitch 5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -9 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 1 by 2 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.8000000000000007 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 3.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 0.5 and relative pitch -3.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 4 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 10 by -7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.125 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [12].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 7 with duration 1.0 and relative pitch -4.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 14 with duration 0.05 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 13 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 12 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 11 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 10 by 0.19999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by -6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.6000000000000001 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 0.5 and relative pitch -5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 5 by 6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 4 by a factor of 2.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.04999999999999999 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 0.5 and relative pitch 4.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 7 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.04999999999999999 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by 1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 2 with duration 0.8 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 1 by 1.5999999999999994 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.2000000000000002 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 1 with duration 0.25 and relative pitch -2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -11 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by 6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 1 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 0.25 and relative pitch -5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -15 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 5 by -4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 5 by a factor of 2.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.04999999999999982 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.20000000000000018 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 0.5 and relative pitch 4.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.05 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 5 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.2 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 9 by -4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 12 by a factor of 2.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 12 by 0.39800000000000013 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 0.25 and relative pitch 3.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 13 by 0.25000000000000044 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -5 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 7 by -2 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 2 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 7 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 3 with duration 0.25 and relative pitch 2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 8 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 1 by -3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 2 by 0.8000000000000007 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 2.6 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 0.25 and relative pitch -6.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -15 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 2 by 7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 1 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.2999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 1.0 and relative pitch 4.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 2 by -4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 2.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.35 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 4 with duration 0.5 and relative pitch 5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 7 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 8 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 6 by -3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 4 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 9 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [8].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 3 with duration 1.0 and relative pitch 2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 10 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 9 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -10 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by 5 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 2 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 3 with duration 0.5 and relative pitch -1.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -14 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by -4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 1 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.125 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 0.25 and relative pitch 5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 7 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 5 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by -8 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 2.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 8 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 7 by 0.4 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 1.0 and relative pitch 2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 9 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 8 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 7 by 0.4 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by -7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 4 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 1.6 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.3999999999999999 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 0.25 and relative pitch 2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by 7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 9 with duration 0.15 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 8 by 0.15000000000000072 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [6].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 7 with duration 0.5 and relative pitch -2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 10 with duration 0.15 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 9 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 8 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 11 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 2 by 0 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 1 by a factor of 2.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 2 by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.2000000000000002 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 0.25 and relative pitch -2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by 5 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.40000000000000036 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.7999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 1.0 and relative pitch 3.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 4 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.8 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by -2 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 0.25 and relative pitch -6.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -16 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by -3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.1 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.2999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 1.0 and relative pitch -5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 3 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 2 by 0.7 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 8 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 7 by -1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 2 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 7 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 5 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 4 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.10000000000000009 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [6].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 5 with duration 0.25 and relative pitch -1.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 8 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 2 by -8 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 4 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 10 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [10].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.9500000000000002 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 0.25 and relative pitch -6.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 11 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -16 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by 3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 4 with duration 0.5 and relative pitch -3.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 9 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 1 by -6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 4 with duration 1.0 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 3 with duration 1.0 and relative pitch 3.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 5 with duration 1.0 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -10 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 1 by -5 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 8 by a factor of 2.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 8 by 0.04999999999999982 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.20000000000000018 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 4 with duration 1.0 and relative pitch -1.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 9 with duration 0.05 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 8 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 7 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.19999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -5 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 6 by 1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 2 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 3 with duration 0.5 and relative pitch -2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 7 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 6 by -7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 5 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 9 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.10000000000000009 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 3 with duration 0.25 and relative pitch 4.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 10 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 14 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 1 by 6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 1 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 2 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 0.25 and relative pitch 2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -2 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 1 by 2 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.09999999999999964 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 0.25 and relative pitch -4.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 11 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by 5 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 7 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.10000000000000009 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 5 with duration 1.0 and relative pitch -6.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 8 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 7 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 0.30000000000000004 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 8 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by 4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.40000000000000036 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.20000000000000018 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 0.25 and relative pitch 1.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 4 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.04999999999999999 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -5 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 5 by -3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 2.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.2000000000000005 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 6 with duration 0.25 and relative pitch 4.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 7 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -16 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 7 by 7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 2 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 13 by 0.125 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [9].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 10 with duration 0.25 and relative pitch 1.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 14 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 13 by 0.04999999999999999 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 1 by 6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 2 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 3 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 2 by 0.3 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.20000000000000018 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 0.5 and relative pitch 2.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 4 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.3 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by 2 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 1 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.6 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 1 with duration 0.5 and relative pitch -3.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 7 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 6 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 5 by 7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 0 by a factor of 2.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 5 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 4 by 0.5999999999999999 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.7999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 4 with duration 0.5 and relative pitch -1.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.3 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 2 by -3 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 1 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 1 with duration 0.5 and relative pitch 4.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 12 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 1 by 0 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 2 by a factor of 3.0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 2 by 3.200000000000001 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.4 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 0.5 and relative pitch 3.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -12 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 3 by 4 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 1 by a factor of 1.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 5 with duration 0.5 and relative pitch 4.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 6 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 5 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by -1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by 1 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 3 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [7].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 0 with duration 1.0 and relative pitch 0.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 12 with duration 0.225 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 11 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 10 with duration 0.125 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Removed note 9 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 8 by 0.15000000000000002 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Transposing non-rest notes by 6 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Shifting note at index 0 by -7 semitones.\n",
      "[2024-09-29 15:12:51] [DEBUG] Scaling duration of note at index 1 by a factor of 0.5.\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:12:51] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:12:51] [DEBUG] Inserting note at index 2 with duration 0.25 and relative pitch 4.\n",
      "[2024-09-29 15:12:51] [DEBUG] Truncated note 3 by 0.25 to maintain total duration.\n",
      "C:\\Users\\cunn2\\AppData\\Local\\Temp\\ipykernel_181064\\2801701428.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  encoder.load_state_dict(torch.load(\"sms/exp1/runs/run_20240926_162652/pretrain_saved_model.pth\"))\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 0-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m encoder \u001b[38;5;241m=\u001b[39m build_encoder(cfg\u001b[38;5;241m.\u001b[39mmodel_dump())\n\u001b[0;32m     13\u001b[0m encoder\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msms/exp1/runs/run_20240926_162652/pretrain_saved_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m---> 15\u001b[0m \u001b[43mcreate_embedding_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[29], line 77\u001b[0m, in \u001b[0;36mcreate_embedding_dict\u001b[1;34m(data_dict, dumped_lp_config, model)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03mCreate the embedding dictionary for the given model. The dumped_lp_config is used to determine the input format of the model.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03mReturns the data_dict, but with embeddings instead of the original data.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     76\u001b[0m formatter \u001b[38;5;241m=\u001b[39m InputFormatter(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdumped_lp_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 77\u001b[0m formatted_data_list \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     78\u001b[0m formatted_data_stacked \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(formatted_data_list, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# shape [num_chunks, *input_shape]\u001b[39;00m\n\u001b[0;32m     79\u001b[0m embeddings_stacked \u001b[38;5;241m=\u001b[39m model(formatted_data_stacked)\n",
      "Cell \u001b[1;32mIn[29], line 77\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03mCreate the embedding dictionary for the given model. The dumped_lp_config is used to determine the input format of the model.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03mReturns the data_dict, but with embeddings instead of the original data.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     76\u001b[0m formatter \u001b[38;5;241m=\u001b[39m InputFormatter(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdumped_lp_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 77\u001b[0m formatted_data_list \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mcopy()) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m data_dict\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[0;32m     78\u001b[0m formatted_data_stacked \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(formatted_data_list, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# shape [num_chunks, *input_shape]\u001b[39;00m\n\u001b[0;32m     79\u001b[0m embeddings_stacked \u001b[38;5;241m=\u001b[39m model(formatted_data_stacked)\n",
      "File \u001b[1;32mc:\\Users\\cunn2\\OneDrive\\DSML\\Project\\thesis-repo\\sms\\src\\synthetic_data\\formatter.py:45\u001b[0m, in \u001b[0;36mInputFormatter.__call__\u001b[1;34m(self, note_array)\u001b[0m\n\u001b[0;32m     43\u001b[0m note_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(note_array)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_piano_roll:\n\u001b[1;32m---> 45\u001b[0m     note_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_piano_roll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnote_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_normalize_octave:\n\u001b[0;32m     47\u001b[0m     note_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_octave(note_array)\n",
      "File \u001b[1;32mc:\\Users\\cunn2\\OneDrive\\DSML\\Project\\thesis-repo\\sms\\src\\synthetic_data\\formatter.py:118\u001b[0m, in \u001b[0;36mInputFormatter.make_piano_roll\u001b[1;34m(self, note_array)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03mConverts a note_array in form [duration, pitch] to a piano roll representation.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03mnp.ndarray: A 2D numpy array, shape (128, steps_per_bar), representing the piano roll.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m steps_per_bar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_bar\n\u001b[1;32m--> 118\u001b[0m quantized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnote_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m piano_roll \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m128\u001b[39m, steps_per_bar), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, pitch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(quantized):\n",
      "File \u001b[1;32mc:\\Users\\cunn2\\OneDrive\\DSML\\Project\\thesis-repo\\sms\\src\\synthetic_data\\formatter.py:88\u001b[0m, in \u001b[0;36mInputFormatter.quantize\u001b[1;34m(self, note_array)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# change the duration to 4 units per bar to steps_per_bar per bar\u001b[39;00m\n\u001b[0;32m     87\u001b[0m note_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(note_array)\n\u001b[1;32m---> 88\u001b[0m \u001b[43mnote_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m steps_per_bar\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# add cumulative duration column\u001b[39;00m\n\u001b[0;32m     91\u001b[0m cumulative_duration \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(note_array[:, \u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 0-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "# data_ids = [str(uuid4()) for _ in range(len(data))]\n",
    "# data_dict = dict(zip(data_ids, data))\n",
    "# filtered_data = [arr for arr in data if arr.shape[0] > 2]\n",
    "# filtered_data_ids = [str(uuid4()) for _ in range(len(filtered_data))]\n",
    "# filtered_data_dict = dict(zip(filtered_data_ids, filtered_data))\n",
    "\n",
    "# num_loops = 100\n",
    "# anchor_keys = np.random.choice(filtered_data_ids, size=num_loops, replace=False)\n",
    "# augmented_data = create_augmented_data(filtered_data_dict, anchor_keys)\n",
    "\n",
    "# cfg = load_config_from_launchplan(\"sms/exp1/runs/run_20240926_162652/original_launchplan.yaml\")\n",
    "# encoder = build_encoder(cfg.model_dump())\n",
    "# encoder.load_state_dict(torch.load(\"sms/exp1/runs/run_20240926_162652/pretrain_saved_model.pth\"))\n",
    "\n",
    "# create_embedding_dict(augmented_data, cfg.model_dump(), encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_augmented_data = []\n",
    "for key1, dict1 in augmented_data.items():\n",
    "    for key2, arr in dict1.items():\n",
    "        flattened_augmented_data.append(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.6000, 88.0000],\n",
       "         [ 0.5000, 88.0000],\n",
       "         [ 0.5000, 87.0000],\n",
       "         [ 0.5000, 85.0000],\n",
       "         [ 0.5000, 84.0000],\n",
       "         [ 1.0000, 85.0000],\n",
       "         [ 0.4000, 85.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 75.0000],\n",
       "         [ 0.5000, 75.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 0.4000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 75.0000],\n",
       "         [ 0.5000, 75.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 0.6500, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 75.0000],\n",
       "         [ 0.5000, 75.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 0.9000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 70.0000],\n",
       "         [ 0.6000, 75.0000],\n",
       "         [ 0.5000, 75.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.9000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 74.0000],\n",
       "         [ 1.0000, 73.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.6000, 73.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 79.0000],\n",
       "         [ 1.0000, 78.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 0.5000, 84.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 0.6000, 78.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 79.0000],\n",
       "         [ 1.0000, 78.0000],\n",
       "         [ 1.0000, 78.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 0.1000, 78.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 79.0000],\n",
       "         [ 1.0000, 78.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 1.1000, 78.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 79.0000],\n",
       "         [ 1.0000, 80.0000],\n",
       "         [ 1.0000, 78.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.1000, 78.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 92.0000],\n",
       "         [ 0.5000, 90.0000],\n",
       "         [ 1.5000, 90.0000],\n",
       "         [ 0.5000, 88.0000],\n",
       "         [ 1.2000, 88.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 81.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 1.5000, 79.0000],\n",
       "         [ 0.5000, 77.0000],\n",
       "         [ 1.2000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 81.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 1.5000, 79.0000],\n",
       "         [ 0.5000, 77.0000],\n",
       "         [ 1.2000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 81.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 1.5000, 79.0000],\n",
       "         [ 1.7000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 81.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 1.5000, 79.0000],\n",
       "         [ 0.5000, 77.0000],\n",
       "         [ 0.9500, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 80.0000],\n",
       "         [ 2.1670, 82.0000],\n",
       "         [ 0.1670, 85.0000],\n",
       "         [ 0.1670, 82.0000],\n",
       "         [ 0.2500, 78.0000],\n",
       "         [ 0.2500, 78.0000],\n",
       "         [ 0.1670, 82.0000],\n",
       "         [ 0.1670, 85.0000],\n",
       "         [ 0.1670, 82.0000],\n",
       "         [ 0.1980, 78.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 69.0000],\n",
       "         [ 2.1670, 71.0000],\n",
       "         [ 0.1670, 74.0000],\n",
       "         [ 0.1670, 71.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.1670, 73.0000],\n",
       "         [ 0.1670, 74.0000],\n",
       "         [ 0.1670, 71.0000],\n",
       "         [ 0.1980, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 69.0000],\n",
       "         [ 2.1670, 71.0000],\n",
       "         [ 0.1670, 74.0000],\n",
       "         [ 0.1670, 71.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.1670, 71.0000],\n",
       "         [ 0.1670, 74.0000],\n",
       "         [ 0.1670, 71.0000],\n",
       "         [ 0.1980, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 69.0000],\n",
       "         [ 2.1670, 71.0000],\n",
       "         [ 0.1670, 74.0000],\n",
       "         [ 0.1670, 71.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.1670, 74.0000],\n",
       "         [ 0.1670, 71.0000],\n",
       "         [ 0.3650, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 69.0000],\n",
       "         [ 2.1670, 71.0000],\n",
       "         [ 0.1670, 74.0000],\n",
       "         [ 0.1670, 71.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 65.0000],\n",
       "         [ 0.1670, 71.0000],\n",
       "         [ 0.1670, 74.0000],\n",
       "         [ 0.1150, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7000, 62.0000],\n",
       "         [ 0.5000, 60.0000],\n",
       "         [ 1.0000, 59.0000],\n",
       "         [ 1.0000, 57.0000],\n",
       "         [ 0.8000, 55.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7000, 74.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.8000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7000, 74.0000],\n",
       "         [ 1.5000, 72.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 0.8000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7000, 74.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 1.8000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7000, 74.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.8000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 69.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 1.8000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.8000, 73.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 72.0000],\n",
       "         [ 2.0000, 74.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.8000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 2.8000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 72.0000],\n",
       "         [ 1.0000, 70.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.8000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 80.0000],\n",
       "         [ 1.0000, 78.0000],\n",
       "         [ 1.0000, 83.0000],\n",
       "         [ 1.8000, 83.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 71.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 1.0000, 70.0000],\n",
       "         [ 1.8000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 71.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 2.0000, 74.0000],\n",
       "         [ 0.8000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 1., 69.],\n",
       "         [ 1., 74.],\n",
       "         [ 2., 74.]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 68.0000],\n",
       "         [ 0.2000, 71.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.3000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 91.0000],\n",
       "         [ 0.5000, 91.0000],\n",
       "         [ 1.0000, 89.0000],\n",
       "         [ 0.7500, 86.0000],\n",
       "         [ 0.2500, 86.0000],\n",
       "         [ 0.5000, 89.0000],\n",
       "         [ 0.5000, 89.0000],\n",
       "         [ 0.2000, 91.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 76.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.7500, 71.0000],\n",
       "         [ 0.2500, 66.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 76.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.7500, 71.0000],\n",
       "         [ 0.2500, 71.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.4500, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 76.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.7500, 71.0000],\n",
       "         [ 0.2500, 71.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.7000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 71.0000],\n",
       "         [ 0.3000, 76.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.7500, 71.0000],\n",
       "         [ 0.2500, 71.0000],\n",
       "         [ 0.2000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 86.0000],\n",
       "         [ 1.5000, 84.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.5000, 82.0000],\n",
       "         [ 0.5000, 82.0000],\n",
       "         [ 0.5000, 82.0000],\n",
       "         [ 0.4000, 82.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 76.0000],\n",
       "         [ 1.5000, 74.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.4000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 76.0000],\n",
       "         [ 1.5000, 74.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.4000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 76.0000],\n",
       "         [ 1.5000, 74.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.9000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 76.0000],\n",
       "         [ 1.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.4000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 79.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 2.2500, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 75.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 0.5000, 70.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 2.2500, 70.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 75.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 70.0000],\n",
       "         [ 0.5000, 70.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 2.5000, 70.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 75.0000],\n",
       "         [ 0.2500, 70.0000],\n",
       "         [ 0.5000, 70.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 2.5000, 70.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 75.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 70.0000],\n",
       "         [ 0.5000, 70.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 1.7500, 70.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3500, 53.0000],\n",
       "         [ 0.2500, 63.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 65.0000],\n",
       "         [ 0.2500, 75.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 87.0000],\n",
       "         [ 0.2500, 86.0000],\n",
       "         [ 0.5000, 77.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 82.0000],\n",
       "         [ 0.2500, 93.0000],\n",
       "         [ 0.1500, 91.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3500, 52.0000],\n",
       "         [ 0.2500, 57.0000],\n",
       "         [ 0.2500, 56.0000],\n",
       "         [ 0.2500, 59.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 68.0000],\n",
       "         [ 0.2500, 71.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 80.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.2500, 75.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 87.0000],\n",
       "         [ 0.1500, 85.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.0500, 47.0000],\n",
       "         [ 0.2500, 57.0000],\n",
       "         [ 0.2500, 56.0000],\n",
       "         [ 0.2500, 59.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 68.0000],\n",
       "         [ 0.2500, 71.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 80.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.2500, 75.0000],\n",
       "         [ 0.2000, 73.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3500, 47.0000],\n",
       "         [ 0.2500, 57.0000],\n",
       "         [ 0.2500, 56.0000],\n",
       "         [ 0.2500, 59.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 68.0000],\n",
       "         [ 0.2500, 71.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.2500, 75.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 87.0000],\n",
       "         [ 0.4000, 85.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3500, 47.0000],\n",
       "         [ 0.2500, 57.0000],\n",
       "         [ 0.2500, 56.0000],\n",
       "         [ 0.2500, 59.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 68.0000],\n",
       "         [ 0.2500, 71.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 80.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.2500, 75.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.5000, 80.0000],\n",
       "         [ 0.1500, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 85.0000],\n",
       "         [ 1.0000, 87.0000],\n",
       "         [ 0.5000, 87.0000],\n",
       "         [ 0.5000, 87.0000],\n",
       "         [ 0.2500, 80.0000],\n",
       "         [ 0.2500, 80.0000],\n",
       "         [ 0.5000, 82.0000],\n",
       "         [ 0.5000, 84.0000],\n",
       "         [ 0.1000, 85.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.1000, 73.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.6000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.6000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.1000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5500, 78.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.5000, 75.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 78.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 75.0000],\n",
       "         [ 1.0000, 76.0000],\n",
       "         [ 0.2000, 64.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5500, 83.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.2000, 62.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5500, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.2000, 62.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5500, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 1.2000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5500, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 1.0000, 65.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.2000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7500, 71.0000],\n",
       "         [ 0.2500, 63.0000],\n",
       "         [ 0.5000, 68.0000],\n",
       "         [ 0.5000, 70.0000],\n",
       "         [ 0.2500, 71.0000],\n",
       "         [ 0.2500, 68.0000],\n",
       "         [ 0.7500, 72.0000],\n",
       "         [ 0.2500, 68.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.2500, 52.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7500, 77.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.7500, 78.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 58.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3750, 77.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.7500, 78.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.6250, 58.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7500, 77.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.7500, 78.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.5000, 58.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7500, 77.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.7500, 78.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 53.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.9000, 68.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 1.0000, 65.0000],\n",
       "         [ 1.0000, 61.0000],\n",
       "         [ 0.6000, 61.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.9000, 74.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 1.0000, 59.0000],\n",
       "         [ 0.6000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.9000, 74.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 1.1000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.9000, 74.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.0000, 67.0000],\n",
       "         [ 1.6000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.9000, 74.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 0.2500, 68.0000],\n",
       "         [ 1.0000, 67.0000],\n",
       "         [ 0.3500, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1500, 78.0000],\n",
       "         [ 0.2500, 78.0000],\n",
       "         [ 2.0000, 77.0000],\n",
       "         [ 1.0000, 77.0000],\n",
       "         [ 0.6000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1500, 72.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 2.0000, 71.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 0.6000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1500, 72.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 1.6000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1500, 72.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 2.6000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 74.0000],\n",
       "         [ 0.1500, 72.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 2.0000, 71.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 0.3500, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 89.0000],\n",
       "         [ 0.2500, 87.0000],\n",
       "         [ 0.2500, 86.0000],\n",
       "         [ 1.5000, 87.0000],\n",
       "         [ 0.2500, 90.0000],\n",
       "         [ 0.2500, 92.0000],\n",
       "         [ 0.5000, 94.0000],\n",
       "         [ 0.2500, 94.0000],\n",
       "         [ 0.2500, 94.0000],\n",
       "         [ 0.1000, 94.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 65.0000],\n",
       "         [ 1.5000, 74.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.1000, 81.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 1.5000, 74.0000],\n",
       "         [ 0.3750, 77.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2250, 81.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 1.5000, 74.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.3500, 81.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 76.0000],\n",
       "         [ 1.0000, 73.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 1.5000, 74.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.1000, 81.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 91.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 87.0000],\n",
       "         [ 0.2500, 86.0000],\n",
       "         [ 0.2500, 87.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 86.0000],\n",
       "         [ 1.5000, 87.0000],\n",
       "         [ 0.5000, 87.0000],\n",
       "         [ 0.3000, 87.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 81.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 71.0000],\n",
       "         [ 1.5000, 77.0000],\n",
       "         [ 0.5000, 77.0000],\n",
       "         [ 0.3000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 81.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 1.5000, 77.0000],\n",
       "         [ 0.8000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 81.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 1.5000, 77.0000],\n",
       "         [ 0.5000, 77.0000],\n",
       "         [ 0.5500, 77.0000]], dtype=torch.float64),\n",
       " tensor([[2.0000e-01, 8.1000e+01],\n",
       "         [2.5000e-01, 8.1000e+01],\n",
       "         [2.5000e-01, 7.9000e+01],\n",
       "         [2.5000e-01, 7.7000e+01],\n",
       "         [2.5000e-01, 7.6000e+01],\n",
       "         [2.5000e-01, 7.7000e+01],\n",
       "         [2.5000e-01, 7.9000e+01],\n",
       "         [2.5000e-01, 7.6000e+01],\n",
       "         [1.5000e+00, 7.7000e+01],\n",
       "         [5.0000e-01, 7.7000e+01],\n",
       "         [5.0000e-02, 7.7000e+01]], dtype=torch.float64),\n",
       " tensor([[ 0.7000, 59.0000],\n",
       "         [ 2.0000, 52.0000],\n",
       "         [ 1.0000, 62.0000],\n",
       "         [ 0.3000, 61.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7000, 69.0000],\n",
       "         [ 2.0000, 62.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 0.3000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7000, 69.0000],\n",
       "         [ 2.0000, 62.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.8000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7000, 69.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 2.3000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7000, 69.0000],\n",
       "         [ 2.0000, 62.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.8000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[5.0000e-02, 7.8000e+01],\n",
       "         [2.5000e-01, 8.0000e+01],\n",
       "         [2.5000e-01, 7.8000e+01],\n",
       "         [2.5000e-01, 7.7000e+01],\n",
       "         [5.0000e-01, 7.5000e+01],\n",
       "         [5.0000e-01, 7.2000e+01],\n",
       "         [5.0000e-01, 7.5000e+01],\n",
       "         [3.7500e-01, 7.5000e+01],\n",
       "         [1.2500e-01, 7.5000e+01],\n",
       "         [1.2000e+00, 7.5000e+01]], dtype=torch.float64),\n",
       " tensor([[5.0000e-02, 7.7000e+01],\n",
       "         [2.5000e-01, 7.5000e+01],\n",
       "         [2.5000e-01, 7.7000e+01],\n",
       "         [2.5000e-01, 7.6000e+01],\n",
       "         [5.0000e-01, 7.4000e+01],\n",
       "         [5.0000e-01, 7.1000e+01],\n",
       "         [5.0000e-01, 7.4000e+01],\n",
       "         [3.7500e-01, 7.4000e+01],\n",
       "         [1.2500e-01, 7.4000e+01],\n",
       "         [1.2000e+00, 7.4000e+01]], dtype=torch.float64),\n",
       " tensor([[5.0000e-02, 7.7000e+01],\n",
       "         [2.5000e-01, 7.9000e+01],\n",
       "         [2.5000e-01, 7.7000e+01],\n",
       "         [2.5000e-01, 7.6000e+01],\n",
       "         [5.0000e-01, 7.4000e+01],\n",
       "         [5.0000e-01, 7.1000e+01],\n",
       "         [5.0000e-01, 7.4000e+01],\n",
       "         [7.5000e-01, 7.4000e+01],\n",
       "         [1.2500e-01, 7.4000e+01],\n",
       "         [8.2500e-01, 7.4000e+01]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 79.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.3750, 74.0000],\n",
       "         [ 0.1250, 74.0000],\n",
       "         [ 1.2500, 74.0000]], dtype=torch.float64),\n",
       " tensor([[5.0000e-02, 7.7000e+01],\n",
       "         [2.5000e-01, 7.9000e+01],\n",
       "         [1.0000e+00, 7.9000e+01],\n",
       "         [2.5000e-01, 7.7000e+01],\n",
       "         [2.5000e-01, 7.6000e+01],\n",
       "         [5.0000e-01, 7.4000e+01],\n",
       "         [5.0000e-01, 7.1000e+01],\n",
       "         [5.0000e-01, 7.4000e+01],\n",
       "         [3.7500e-01, 7.4000e+01],\n",
       "         [1.2500e-01, 7.4000e+01],\n",
       "         [2.0000e-01, 7.4000e+01]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 59.0000],\n",
       "         [ 0.5000, 63.0000],\n",
       "         [ 0.5000, 61.0000],\n",
       "         [ 0.5000, 59.0000],\n",
       "         [ 0.5000, 57.0000],\n",
       "         [ 0.5000, 56.0000],\n",
       "         [ 0.5000, 57.0000],\n",
       "         [ 0.5000, 61.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 74.0000],\n",
       "         [ 0.5000, 77.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 74.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 1.5000, 72.0000],\n",
       "         [ 0.5000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 74.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.0000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 74.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.2500, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 91.0000],\n",
       "         [ 0.5000, 92.0000],\n",
       "         [ 1.0000, 94.0000],\n",
       "         [ 0.5000, 96.0000],\n",
       "         [ 0.5000, 94.0000],\n",
       "         [ 0.5000, 92.0000],\n",
       "         [ 0.5000, 91.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 78.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 1.0000, 81.0000],\n",
       "         [ 0.5000, 83.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 0.5000, 78.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 78.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 1.0000, 81.0000],\n",
       "         [ 1.5000, 83.0000],\n",
       "         [ 0.5000, 81.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 78.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 1.0000, 81.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 1.0000, 78.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 78.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 1.0000, 81.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.5000, 83.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.5000, 79.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 76.0000],\n",
       "         [ 0.7500, 73.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 2.0000, 74.0000],\n",
       "         [ 0.8000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 76.0000],\n",
       "         [ 0.7500, 73.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 2.0000, 79.0000],\n",
       "         [ 0.8000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 76.0000],\n",
       "         [ 0.7500, 73.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 2.0000, 74.0000],\n",
       "         [ 0.8000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 76.0000],\n",
       "         [ 0.7500, 73.0000],\n",
       "         [ 2.0000, 74.0000],\n",
       "         [ 1.0500, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 76.0000],\n",
       "         [ 0.7500, 73.0000],\n",
       "         [ 1.0000, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 1.8000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 57.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2000, 73.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 57.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2000, 73.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.6000, 57.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.4000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 57.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.7000, 73.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 57.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 1.0000, 70.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.2000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 1., 89.],\n",
       "         [ 2., 89.],\n",
       "         [ 1., 89.]], dtype=torch.float64),\n",
       " tensor([[ 1., 79.],\n",
       "         [ 2., 76.],\n",
       "         [ 1., 76.]], dtype=torch.float64),\n",
       " tensor([[ 1., 76.],\n",
       "         [ 2., 76.],\n",
       "         [ 1., 76.]], dtype=torch.float64),\n",
       " tensor([[ 1., 76.],\n",
       "         [ 3., 76.]], dtype=torch.float64),\n",
       " tensor([[ 1., 76.],\n",
       "         [ 1., 71.],\n",
       "         [ 2., 76.]], dtype=torch.float64),\n",
       " tensor([[5.0000e-02, 6.3000e+01],\n",
       "         [2.5000e-01, 6.3000e+01],\n",
       "         [1.2500e-01, 6.1000e+01],\n",
       "         [1.2500e-01, 6.1000e+01],\n",
       "         [1.2500e-01, 6.1000e+01],\n",
       "         [1.2500e-01, 6.1000e+01],\n",
       "         [2.5000e-01, 6.6000e+01],\n",
       "         [2.5000e-01, 6.6000e+01],\n",
       "         [2.5000e-01, 6.5000e+01],\n",
       "         [2.5000e-01, 6.1000e+01],\n",
       "         [5.0000e-01, 6.3000e+01],\n",
       "         [5.0000e-01, 6.1000e+01],\n",
       "         [2.5000e-01, 6.1000e+01],\n",
       "         [1.2500e-01, 6.1000e+01],\n",
       "         [1.2500e-01, 6.1000e+01],\n",
       "         [2.5000e-01, 6.1000e+01],\n",
       "         [1.2500e-01, 6.1000e+01],\n",
       "         [1.2500e-01, 6.1000e+01],\n",
       "         [2.0000e-01, 6.0000e+01]], dtype=torch.float64),\n",
       " tensor([[5.0000e-02, 6.9000e+01],\n",
       "         [2.5000e-01, 6.9000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [2.5000e-01, 7.2000e+01],\n",
       "         [2.5000e-01, 7.2000e+01],\n",
       "         [2.5000e-01, 7.1000e+01],\n",
       "         [2.5000e-01, 6.7000e+01],\n",
       "         [5.0000e-01, 6.9000e+01],\n",
       "         [5.0000e-01, 6.7000e+01],\n",
       "         [2.5000e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [2.5000e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [2.0000e-01, 6.6000e+01]], dtype=torch.float64),\n",
       " tensor([[5.0000e-02, 6.9000e+01],\n",
       "         [2.5000e-01, 6.9000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [2.5000e-01, 7.2000e+01],\n",
       "         [2.5000e-01, 7.2000e+01],\n",
       "         [2.5000e-01, 7.1000e+01],\n",
       "         [2.5000e-01, 6.7000e+01],\n",
       "         [5.0000e-01, 6.9000e+01],\n",
       "         [5.0000e-01, 6.7000e+01],\n",
       "         [2.5000e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [2.5000e-01, 6.7000e+01],\n",
       "         [2.5000e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [7.5000e-02, 6.6000e+01]], dtype=torch.float64),\n",
       " tensor([[5.0000e-02, 6.9000e+01],\n",
       "         [2.5000e-01, 6.9000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [2.5000e-01, 7.2000e+01],\n",
       "         [2.5000e-01, 7.2000e+01],\n",
       "         [2.5000e-01, 7.1000e+01],\n",
       "         [2.5000e-01, 6.7000e+01],\n",
       "         [5.0000e-01, 6.9000e+01],\n",
       "         [5.0000e-01, 6.7000e+01],\n",
       "         [2.5000e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [2.5000e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [3.2500e-01, 6.7000e+01]], dtype=torch.float64),\n",
       " tensor([[5.0000e-02, 6.9000e+01],\n",
       "         [2.5000e-01, 6.9000e+01],\n",
       "         [2.5000e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [2.5000e-01, 7.2000e+01],\n",
       "         [2.5000e-01, 7.2000e+01],\n",
       "         [2.5000e-01, 7.1000e+01],\n",
       "         [2.5000e-01, 6.7000e+01],\n",
       "         [5.0000e-01, 6.9000e+01],\n",
       "         [5.0000e-01, 6.7000e+01],\n",
       "         [2.5000e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [2.5000e-01, 6.7000e+01],\n",
       "         [1.2500e-01, 6.7000e+01],\n",
       "         [7.5000e-02, 6.7000e+01]], dtype=torch.float64),\n",
       " tensor([[ 1.4000, 74.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.6000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.4000, 76.0000],\n",
       "         [ 1.0000, 76.0000],\n",
       "         [ 1.0000, 76.0000],\n",
       "         [ 0.6000, 70.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.4000, 76.0000],\n",
       "         [ 1.0000, 76.0000],\n",
       "         [ 1.0000, 76.0000],\n",
       "         [ 0.6000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 1., 76.],\n",
       "         [ 1., 76.],\n",
       "         [ 2., 74.]], dtype=torch.float64),\n",
       " tensor([[ 1.4000, 76.0000],\n",
       "         [ 1.0000, 76.0000],\n",
       "         [ 1.0000, 76.0000],\n",
       "         [ 0.6000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 59.0000],\n",
       "         [ 1.0000, 58.0000],\n",
       "         [ 2.2000, 59.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 74.0000],\n",
       "         [ 1.0000, 73.0000],\n",
       "         [ 2.2000, 68.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 74.0000],\n",
       "         [ 1.0000, 73.0000],\n",
       "         [ 2.2000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 74.0000],\n",
       "         [ 3.2000, 73.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 74.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 1.0000, 73.0000],\n",
       "         [ 1.9500, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 86.0000],\n",
       "         [ 0.2500, 87.0000],\n",
       "         [ 0.2500, 86.0000],\n",
       "         [ 0.2500, 87.0000],\n",
       "         [ 0.2500, 86.0000],\n",
       "         [ 0.2500, 90.0000],\n",
       "         [ 0.2500, 91.0000],\n",
       "         [ 0.2500, 86.0000],\n",
       "         [ 0.2500, 85.0000],\n",
       "         [ 0.2500, 86.0000],\n",
       "         [ 0.2500, 85.0000],\n",
       "         [ 0.2500, 86.0000],\n",
       "         [ 0.2500, 85.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 90.0000],\n",
       "         [ 0.2500, 85.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 89.0000],\n",
       "         [ 0.2500, 90.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 90.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 93.0000],\n",
       "         [ 0.2500, 94.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 88.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 88.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 88.0000],\n",
       "         [ 0.2500, 92.0000],\n",
       "         [ 0.2500, 93.0000],\n",
       "         [ 0.2500, 88.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 89.0000],\n",
       "         [ 0.2500, 90.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 90.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 93.0000],\n",
       "         [ 0.2500, 94.0000],\n",
       "         [ 0.5000, 89.0000],\n",
       "         [ 0.2500, 88.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 88.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 88.0000],\n",
       "         [ 0.2500, 92.0000],\n",
       "         [ 0.2500, 93.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 89.0000],\n",
       "         [ 0.2500, 90.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 90.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 93.0000],\n",
       "         [ 0.2500, 94.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 88.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 88.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 88.0000],\n",
       "         [ 0.2500, 93.0000],\n",
       "         [ 0.5000, 88.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 89.0000],\n",
       "         [ 0.2500, 90.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 90.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 93.0000],\n",
       "         [ 0.2500, 94.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 88.0000],\n",
       "         [ 0.5000, 83.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 88.0000],\n",
       "         [ 0.2500, 89.0000],\n",
       "         [ 0.2500, 88.0000],\n",
       "         [ 0.2500, 92.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 61.0000],\n",
       "         [ 0.5000, 60.0000],\n",
       "         [ 1.5000, 63.0000],\n",
       "         [ 0.5000, 56.0000],\n",
       "         [ 0.5000, 58.0000],\n",
       "         [ 0.6000, 56.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 67.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 1.5000, 69.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 56.0000],\n",
       "         [ 0.6000, 62.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 67.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.7500, 69.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 1.3500, 62.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 67.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 1.5000, 69.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 1.1000, 62.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 67.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 1.5000, 69.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.2500, 58.0000],\n",
       "         [ 0.3500, 62.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 67.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.0000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 67.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.0000, 78.0000],\n",
       "         [ 1.0000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 67.0000],\n",
       "         [ 0.2500, 71.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.2500, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 67.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 2.0000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 66.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.0000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 57.0000],\n",
       "         [ 0.5000, 57.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.5000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 61.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 62.0000],\n",
       "         [ 1.5000, 62.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.0000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 73.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.7500, 62.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.7500, 61.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 75.0000],\n",
       "         [ 0.5000, 68.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.7500, 64.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.7500, 63.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 75.0000],\n",
       "         [ 1.0000, 66.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.7500, 64.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.2500, 63.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 75.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.7500, 64.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 1.2500, 63.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 75.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 59.0000],\n",
       "         [ 0.7500, 64.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.5000, 63.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 68.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.2500, 64.0000],\n",
       "         [ 0.2500, 66.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 66.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.5000, 75.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 64.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 66.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 1.5000, 64.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 62.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 66.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.7500, 64.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 66.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 61.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 62.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.3000, 71.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 2.2000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.3000, 75.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 2.2000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.3000, 78.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 2.2000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.3000, 78.0000],\n",
       "         [ 2.7000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 78.0000],\n",
       "         [ 1.3000, 78.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 1.2000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[6.7000e-02, 8.1000e+01],\n",
       "         [3.3300e-01, 8.0000e+01],\n",
       "         [1.5000e+00, 8.0000e+01],\n",
       "         [5.0000e-01, 7.6000e+01],\n",
       "         [1.0000e+00, 8.6000e+01],\n",
       "         [5.0000e-01, 8.4000e+01],\n",
       "         [1.0000e-01, 8.3000e+01]], dtype=torch.float64),\n",
       " tensor([[6.7000e-02, 6.7000e+01],\n",
       "         [3.3300e-01, 6.6000e+01],\n",
       "         [1.5000e+00, 6.6000e+01],\n",
       "         [5.0000e-01, 6.2000e+01],\n",
       "         [1.0000e+00, 7.2000e+01],\n",
       "         [5.0000e-01, 7.2000e+01],\n",
       "         [1.0000e-01, 6.9000e+01]], dtype=torch.float64),\n",
       " tensor([[6.7000e-02, 6.7000e+01],\n",
       "         [3.3300e-01, 6.6000e+01],\n",
       "         [1.5000e+00, 6.6000e+01],\n",
       "         [1.5000e+00, 6.2000e+01],\n",
       "         [6.0000e-01, 7.2000e+01]], dtype=torch.float64),\n",
       " tensor([[6.7000e-02, 6.7000e+01],\n",
       "         [1.5000e+00, 6.6000e+01],\n",
       "         [5.0000e-01, 6.2000e+01],\n",
       "         [1.0000e+00, 7.2000e+01],\n",
       "         [5.0000e-01, 7.0000e+01],\n",
       "         [4.3300e-01, 6.9000e+01]], dtype=torch.float64),\n",
       " tensor([[6.7000e-02, 6.7000e+01],\n",
       "         [3.3300e-01, 6.6000e+01],\n",
       "         [1.5000e+00, 6.6000e+01],\n",
       "         [5.0000e-01, 6.2000e+01],\n",
       "         [1.0000e+00, 7.2000e+01],\n",
       "         [6.0000e-01, 7.3000e+01]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 66.0000],\n",
       "         [ 1.0000, 68.0000],\n",
       "         [ 1.0000, 68.0000],\n",
       "         [ 1.0000, 65.0000],\n",
       "         [ 0.5000, 70.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 70.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.5000, 79.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 70.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 1.0000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 70.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.5000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 70.0000],\n",
       "         [ 0.2500, 70.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.2500, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 64.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.2500, 64.0000],\n",
       "         [ 0.2500, 64.0000],\n",
       "         [ 0.5000, 63.0000],\n",
       "         [ 0.5000, 59.0000],\n",
       "         [ 0.5000, 64.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 67.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.2500, 66.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 67.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 67.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 1.0000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 67.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.5000, 61.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.5000, 62.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 59.0000],\n",
       "         [ 2.0000, 57.0000],\n",
       "         [ 1.0000, 59.0000],\n",
       "         [ 0.4000, 61.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 68.0000],\n",
       "         [ 2.0000, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.4000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.9000, 74.0000],\n",
       "         [ 2.0000, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.1000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 2., 72.],\n",
       "         [ 1., 74.],\n",
       "         [ 1., 76.]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 74.0000],\n",
       "         [ 2.0000, 72.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.1500, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 75.0000],\n",
       "         [ 1.0000, 79.0000],\n",
       "         [ 1.0000, 77.0000],\n",
       "         [ 1.0000, 70.0000],\n",
       "         [ 0.4000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 72.0000],\n",
       "         [ 1.0000, 76.0000],\n",
       "         [ 1.0000, 81.0000],\n",
       "         [ 1.0000, 67.0000],\n",
       "         [ 0.4000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 72.0000],\n",
       "         [ 1.0000, 76.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 1.0000, 67.0000],\n",
       "         [ 0.9000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.0000, 67.0000],\n",
       "         [ 1.4000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 72.0000],\n",
       "         [ 1.0000, 76.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.4000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 89.0000],\n",
       "         [ 0.2500, 86.0000],\n",
       "         [ 0.2500, 82.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 84.0000],\n",
       "         [ 1.0000, 82.0000],\n",
       "         [ 0.2500, 82.0000],\n",
       "         [ 0.2500, 86.0000],\n",
       "         [ 0.5000, 89.0000],\n",
       "         [ 0.5000, 89.0000],\n",
       "         [ 0.1000, 89.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 84.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 1.0000, 77.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.5000, 84.0000],\n",
       "         [ 0.5000, 84.0000],\n",
       "         [ 0.1000, 84.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 84.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 1.0000, 77.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.5000, 84.0000],\n",
       "         [ 0.6000, 84.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 84.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 1.0000, 77.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.5000, 84.0000],\n",
       "         [ 0.6000, 84.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 84.0000],\n",
       "         [ 0.5000, 77.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 1.0000, 77.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.5000, 84.0000],\n",
       "         [ 0.1000, 84.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 79.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.7500, 74.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 1.5000, 72.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 0.3000, 84.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.7500, 72.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 1.5000, 69.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.3000, 81.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.7500, 71.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 1.5000, 69.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.4000, 81.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 1.5000, 69.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 1.0500, 81.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.7500, 71.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 1.5000, 69.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.3000, 78.0000]], dtype=torch.float64),\n",
       " tensor([[ 1., 83.],\n",
       "         [ 2., 88.],\n",
       "         [ 1., 88.]], dtype=torch.float64),\n",
       " tensor([[ 1., 74.],\n",
       "         [ 2., 79.],\n",
       "         [ 1., 77.]], dtype=torch.float64),\n",
       " tensor([[ 3., 74.],\n",
       "         [ 1., 79.]], dtype=torch.float64),\n",
       " tensor([[ 1., 74.],\n",
       "         [ 3., 79.]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 74.0000],\n",
       "         [ 0.2500, 75.0000],\n",
       "         [ 2.0000, 79.0000],\n",
       "         [ 0.7500, 79.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 56.0000],\n",
       "         [ 0.5000, 58.0000],\n",
       "         [ 1.0000, 59.0000],\n",
       "         [ 1.5000, 58.0000],\n",
       "         [ 0.5000, 59.0000],\n",
       "         [ 0.4000, 56.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 67.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 1.0000, 70.0000],\n",
       "         [ 1.5000, 69.0000],\n",
       "         [ 0.5000, 70.0000],\n",
       "         [ 0.4000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 67.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 1.5000, 70.0000],\n",
       "         [ 1.5000, 69.0000],\n",
       "         [ 0.4000, 70.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 67.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 1.5000, 69.0000],\n",
       "         [ 0.5000, 70.0000],\n",
       "         [ 1.4000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 67.0000],\n",
       "         [ 1.0000, 64.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 1.0000, 70.0000],\n",
       "         [ 1.4000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[  0.2500,  73.0000],\n",
       "         [  0.2500,  77.0000],\n",
       "         [  0.2500,  73.0000],\n",
       "         [  0.2500,  73.0000],\n",
       "         [  0.2500,  77.0000],\n",
       "         [  0.2500,  73.0000],\n",
       "         [  0.2500,  77.0000],\n",
       "         [  0.2500,  77.0000],\n",
       "         [  0.2500,  77.0000],\n",
       "         [  0.2500,  69.0000],\n",
       "         [  0.2500,  78.0000],\n",
       "         [  0.7500, 102.0000],\n",
       "         [  0.2500,  95.0000],\n",
       "         [  0.2500,  92.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 58.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 58.0000],\n",
       "         [ 0.2500, 58.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 58.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 59.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 54.0000],\n",
       "         [ 0.2500, 63.0000],\n",
       "         [ 0.7500, 87.0000],\n",
       "         [ 0.2500, 80.0000],\n",
       "         [ 0.2500, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 58.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 58.0000],\n",
       "         [ 0.2500, 58.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 58.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.3750, 54.0000],\n",
       "         [ 0.2500, 63.0000],\n",
       "         [ 0.7500, 87.0000],\n",
       "         [ 0.2500, 80.0000],\n",
       "         [ 0.1250, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 58.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 58.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 58.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 54.0000],\n",
       "         [ 0.2500, 63.0000],\n",
       "         [ 0.7500, 87.0000],\n",
       "         [ 0.2500, 80.0000],\n",
       "         [ 0.5000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 58.0000],\n",
       "         [ 0.5000, 65.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 58.0000],\n",
       "         [ 0.2500, 58.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 58.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 54.0000],\n",
       "         [ 0.2500, 63.0000],\n",
       "         [ 0.7500, 87.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7000, 85.0000],\n",
       "         [ 1.5000, 85.0000],\n",
       "         [ 0.2500, 78.0000],\n",
       "         [ 0.2500, 78.0000],\n",
       "         [ 0.2500, 80.0000],\n",
       "         [ 0.2500, 80.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 0.3000, 80.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7000, 80.0000],\n",
       "         [ 1.5000, 74.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.3000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7000, 74.0000],\n",
       "         [ 1.5000, 74.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.7500, 69.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.3000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.5000, 74.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 1.0000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7000, 74.0000],\n",
       "         [ 1.5000, 74.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.3000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.8000, 72.0000],\n",
       "         [ 0.7500, 72.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 0.2500, 70.0000],\n",
       "         [ 0.3750, 69.0000],\n",
       "         [ 0.1250, 70.0000],\n",
       "         [ 0.2000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.8000, 71.0000],\n",
       "         [ 0.7500, 67.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 65.0000],\n",
       "         [ 0.3750, 64.0000],\n",
       "         [ 0.1250, 65.0000],\n",
       "         [ 0.2000, 64.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.8000, 67.0000],\n",
       "         [ 0.7500, 67.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 65.0000],\n",
       "         [ 0.3750, 64.0000],\n",
       "         [ 0.3250, 65.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7500, 67.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 65.0000],\n",
       "         [ 0.3750, 64.0000],\n",
       "         [ 0.1250, 65.0000],\n",
       "         [ 2.0000, 64.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.8000, 67.0000],\n",
       "         [ 0.7500, 67.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 65.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 65.0000],\n",
       "         [ 0.3750, 64.0000],\n",
       "         [ 0.0750, 65.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 56.0000],\n",
       "         [ 0.5000, 58.0000],\n",
       "         [ 0.5000, 55.0000],\n",
       "         [ 2.0000, 56.0000],\n",
       "         [ 0.8000, 51.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 72.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 2.0000, 72.0000],\n",
       "         [ 0.8000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 72.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 71.0000],\n",
       "         [ 2.0000, 72.0000],\n",
       "         [ 1.0500, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 72.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 2.8000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 72.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 1.8000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 63.0000],\n",
       "         [ 0.5000, 63.0000],\n",
       "         [ 0.5000, 63.0000],\n",
       "         [ 1.5000, 61.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.5000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 72.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 1.5000, 65.0000],\n",
       "         [ 0.5000, 70.0000],\n",
       "         [ 0.5000, 75.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 67.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 1.5000, 65.0000],\n",
       "         [ 0.5000, 70.0000],\n",
       "         [ 0.7500, 75.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 67.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 1.5000, 65.0000],\n",
       "         [ 0.5000, 70.0000],\n",
       "         [ 1.0000, 75.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 67.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.5000, 61.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 1.5000, 65.0000],\n",
       "         [ 0.5000, 70.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 70.0000],\n",
       "         [ 1.0000, 70.0000],\n",
       "         [ 0.7500, 70.0000],\n",
       "         [ 0.2500, 68.0000],\n",
       "         [ 1.0000, 66.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 71.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 0.7500, 71.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 1.0000, 61.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 71.0000],\n",
       "         [ 2.0000, 71.0000],\n",
       "         [ 0.7500, 71.0000],\n",
       "         [ 0.2500, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 71.0000],\n",
       "         [ 0.7500, 71.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 2.0000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 71.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 0.7500, 71.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.5000, 68.0000],\n",
       "         [ 0.5000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1500, 78.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 2.0000, 79.0000],\n",
       "         [ 0.7500, 82.0000],\n",
       "         [ 0.2500, 84.0000],\n",
       "         [ 0.6000, 86.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1500, 67.0000],\n",
       "         [ 0.2500, 71.0000],\n",
       "         [ 2.0000, 69.0000],\n",
       "         [ 0.7500, 72.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.6000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4500, 68.0000],\n",
       "         [ 0.2500, 71.0000],\n",
       "         [ 2.0000, 69.0000],\n",
       "         [ 0.7500, 72.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.3000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1500, 68.0000],\n",
       "         [ 0.2500, 71.0000],\n",
       "         [ 0.7500, 72.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 2.6000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1500, 68.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.2500, 71.0000],\n",
       "         [ 2.0000, 69.0000],\n",
       "         [ 0.7500, 72.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.1000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 63.0000],\n",
       "         [ 1.0000, 61.0000],\n",
       "         [ 2.4000, 60.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 69.0000],\n",
       "         [ 1.0000, 67.0000],\n",
       "         [ 2.4000, 66.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 69.0000],\n",
       "         [ 1.0000, 67.0000],\n",
       "         [ 2.4000, 66.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 69.0000],\n",
       "         [ 3.4000, 66.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 69.0000],\n",
       "         [ 0.5000, 65.0000],\n",
       "         [ 1.0000, 67.0000],\n",
       "         [ 1.9000, 66.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 51.0000],\n",
       "         [ 1.5000, 55.0000],\n",
       "         [ 0.5000, 56.0000],\n",
       "         [ 1.0000, 58.0000],\n",
       "         [ 0.4000, 58.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 67.0000],\n",
       "         [ 1.5000, 71.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.0000, 81.0000],\n",
       "         [ 0.4000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 67.0000],\n",
       "         [ 1.5000, 71.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 0.9000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 67.0000],\n",
       "         [ 1.5000, 71.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.4000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 67.0000],\n",
       "         [ 1.5000, 71.0000],\n",
       "         [ 1.0000, 75.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.4000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 76.0000],\n",
       "         [ 1.0000, 76.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.5000, 66.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 69.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 60.0000],\n",
       "         [ 0.5000, 66.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 69.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 60.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 69.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.5000, 60.0000],\n",
       "         [ 1.0000, 59.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 69.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 1.0000, 67.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.5000, 62.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 82.0000],\n",
       "         [ 1.0000, 84.0000],\n",
       "         [ 0.5000, 87.0000],\n",
       "         [ 0.5000, 84.0000],\n",
       "         [ 1.0000, 81.0000],\n",
       "         [ 0.4000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 75.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 0.5000, 75.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.4000, 65.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 70.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 0.5000, 75.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.9000, 65.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 70.0000],\n",
       "         [ 0.5000, 75.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 1.4000, 65.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 70.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 0.5000, 75.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.2500, 61.0000],\n",
       "         [ 0.1500, 65.0000]], dtype=torch.float64),\n",
       " tensor([[ 2., 75.],\n",
       "         [ 1., 75.],\n",
       "         [ 1., 70.]], dtype=torch.float64),\n",
       " tensor([[ 2., 64.],\n",
       "         [ 1., 64.],\n",
       "         [ 1., 63.]], dtype=torch.float64),\n",
       " tensor([[ 2., 64.],\n",
       "         [ 1., 64.],\n",
       "         [ 1., 59.]], dtype=torch.float64),\n",
       " tensor([[ 2., 64.],\n",
       "         [ 2., 64.]], dtype=torch.float64),\n",
       " tensor([[ 2.0000, 64.0000],\n",
       "         [ 0.5000, 65.0000],\n",
       "         [ 1.0000, 64.0000],\n",
       "         [ 0.5000, 59.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 75.0000],\n",
       "         [ 0.5000, 80.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 0.5000, 77.0000],\n",
       "         [ 0.5000, 75.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.6000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 74.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.6000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 74.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 0.1000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 74.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 1.1000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 74.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 0.5000, 82.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.1000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 78.0000],\n",
       "         [ 1.0000, 80.0000],\n",
       "         [ 1.0000, 82.0000],\n",
       "         [ 1.0000, 80.0000],\n",
       "         [ 0.8000, 78.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 77.0000],\n",
       "         [ 1.0000, 79.0000],\n",
       "         [ 1.0000, 76.0000],\n",
       "         [ 1.0000, 79.0000],\n",
       "         [ 0.8000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 77.0000],\n",
       "         [ 1.0000, 79.0000],\n",
       "         [ 1.0000, 81.0000],\n",
       "         [ 1.0000, 79.0000],\n",
       "         [ 0.4000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 77.0000],\n",
       "         [ 1.0000, 79.0000],\n",
       "         [ 1.0000, 81.0000],\n",
       "         [ 1.8000, 79.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 77.0000],\n",
       "         [ 0.5000, 82.0000],\n",
       "         [ 1.0000, 79.0000],\n",
       "         [ 1.0000, 81.0000],\n",
       "         [ 1.0000, 79.0000],\n",
       "         [ 0.3000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 69.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 0.2000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 72.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.0000, 82.0000],\n",
       "         [ 0.2000, 70.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 72.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.5000, 75.0000],\n",
       "         [ 0.7000, 70.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 72.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.2000, 70.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 72.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.2500, 78.0000],\n",
       "         [ 0.9500, 75.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 68.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.5000, 68.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 2.0000, 71.0000],\n",
       "         [ 0.2000, 68.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 71.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 2.0000, 74.0000],\n",
       "         [ 0.2000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 71.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 2.2000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 71.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 2.0000, 74.0000],\n",
       "         [ 0.7000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 71.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.9500, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 46.0000],\n",
       "         [ 0.2500, 46.0000],\n",
       "         [ 0.2500, 46.0000],\n",
       "         [ 0.5000, 46.0000],\n",
       "         [ 0.5000, 46.0000],\n",
       "         [ 0.5000, 46.0000],\n",
       "         [ 0.2500, 46.0000],\n",
       "         [ 0.2500, 46.0000],\n",
       "         [ 0.5000, 46.0000],\n",
       "         [ 0.2500, 46.0000],\n",
       "         [ 0.2500, 46.0000],\n",
       "         [ 0.4000, 39.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 62.0000],\n",
       "         [ 0.2500, 64.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.4000, 55.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.1500, 55.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.9000, 55.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.4000, 58.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 86.0000],\n",
       "         [ 1.0000, 91.0000],\n",
       "         [ 1.0000, 93.0000],\n",
       "         [ 1.2000, 95.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 72.0000],\n",
       "         [ 1.0000, 77.0000],\n",
       "         [ 1.0000, 79.0000],\n",
       "         [ 1.2000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 72.0000],\n",
       "         [ 2.0000, 77.0000],\n",
       "         [ 1.0000, 79.0000],\n",
       "         [ 0.2000, 81.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 72.0000],\n",
       "         [ 1.0000, 77.0000],\n",
       "         [ 2.2000, 81.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 72.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 1.0000, 77.0000],\n",
       "         [ 1.0000, 79.0000],\n",
       "         [ 0.7000, 81.0000]], dtype=torch.float64),\n",
       " tensor([[5.0000e-02, 5.9000e+01],\n",
       "         [7.5000e-01, 5.6000e+01],\n",
       "         [2.5000e-01, 5.6000e+01],\n",
       "         [2.5000e-01, 5.6000e+01],\n",
       "         [2.5000e-01, 6.1000e+01],\n",
       "         [2.5000e-01, 6.1000e+01],\n",
       "         [2.5000e-01, 6.1000e+01],\n",
       "         [2.5000e-01, 5.8000e+01],\n",
       "         [5.0000e-01, 5.6000e+01],\n",
       "         [2.5000e-01, 5.4000e+01],\n",
       "         [2.5000e-01, 5.6000e+01],\n",
       "         [2.5000e-01, 5.9000e+01],\n",
       "         [2.5000e-01, 5.8000e+01],\n",
       "         [2.0000e-01, 5.6000e+01]], dtype=torch.float64),\n",
       " tensor([[5.0000e-02, 7.2000e+01],\n",
       "         [7.5000e-01, 7.1000e+01],\n",
       "         [2.5000e-01, 6.9000e+01],\n",
       "         [2.5000e-01, 6.9000e+01],\n",
       "         [2.5000e-01, 7.4000e+01],\n",
       "         [2.5000e-01, 7.4000e+01],\n",
       "         [2.5000e-01, 7.4000e+01],\n",
       "         [2.5000e-01, 7.1000e+01],\n",
       "         [5.0000e-01, 6.9000e+01],\n",
       "         [2.5000e-01, 6.7000e+01],\n",
       "         [2.5000e-01, 6.9000e+01],\n",
       "         [2.5000e-01, 7.2000e+01],\n",
       "         [2.5000e-01, 7.1000e+01],\n",
       "         [2.0000e-01, 6.9000e+01]], dtype=torch.float64),\n",
       " tensor([[5.0000e-02, 7.2000e+01],\n",
       "         [7.5000e-01, 6.9000e+01],\n",
       "         [2.5000e-01, 6.9000e+01],\n",
       "         [2.5000e-01, 6.9000e+01],\n",
       "         [2.5000e-01, 7.4000e+01],\n",
       "         [2.5000e-01, 7.4000e+01],\n",
       "         [2.5000e-01, 7.4000e+01],\n",
       "         [2.5000e-01, 7.1000e+01],\n",
       "         [1.0000e+00, 6.9000e+01],\n",
       "         [2.5000e-01, 6.7000e+01],\n",
       "         [2.5000e-01, 6.9000e+01],\n",
       "         [2.0000e-01, 7.2000e+01]], dtype=torch.float64),\n",
       " tensor([[5.0000e-02, 7.2000e+01],\n",
       "         [7.5000e-01, 6.9000e+01],\n",
       "         [2.5000e-01, 6.9000e+01],\n",
       "         [2.5000e-01, 7.4000e+01],\n",
       "         [2.5000e-01, 7.4000e+01],\n",
       "         [2.5000e-01, 7.4000e+01],\n",
       "         [2.5000e-01, 7.1000e+01],\n",
       "         [5.0000e-01, 6.9000e+01],\n",
       "         [2.5000e-01, 6.7000e+01],\n",
       "         [2.5000e-01, 6.9000e+01],\n",
       "         [2.5000e-01, 7.2000e+01],\n",
       "         [2.5000e-01, 7.1000e+01],\n",
       "         [4.5000e-01, 6.9000e+01]], dtype=torch.float64),\n",
       " tensor([[5.0000e-02, 7.2000e+01],\n",
       "         [7.5000e-01, 6.9000e+01],\n",
       "         [2.5000e-01, 6.9000e+01],\n",
       "         [2.5000e-01, 6.9000e+01],\n",
       "         [2.5000e-01, 7.4000e+01],\n",
       "         [2.5000e-01, 7.8000e+01],\n",
       "         [2.5000e-01, 7.4000e+01],\n",
       "         [2.5000e-01, 7.4000e+01],\n",
       "         [2.5000e-01, 7.1000e+01],\n",
       "         [5.0000e-01, 6.9000e+01],\n",
       "         [2.5000e-01, 6.7000e+01],\n",
       "         [2.5000e-01, 6.9000e+01],\n",
       "         [2.5000e-01, 7.2000e+01],\n",
       "         [2.0000e-01, 7.1000e+01]], dtype=torch.float64),\n",
       " tensor([[ 1., 79.],\n",
       "         [ 1., 82.],\n",
       "         [ 2., 79.]], dtype=torch.float64),\n",
       " tensor([[ 1., 65.],\n",
       "         [ 1., 74.],\n",
       "         [ 2., 71.]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 71.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 2.5000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 1., 71.],\n",
       "         [ 3., 71.]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 71.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.5000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 50.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.5000, 59.0000],\n",
       "         [ 0.2500, 66.0000],\n",
       "         [ 0.2500, 64.0000],\n",
       "         [ 0.2500, 59.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 61.0000],\n",
       "         [ 0.2500, 60.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 59.0000],\n",
       "         [ 0.2500, 58.0000],\n",
       "         [ 0.7500, 57.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 64.0000],\n",
       "         [ 0.2500, 71.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.2500, 80.0000],\n",
       "         [ 0.2500, 78.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 75.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 0.7500, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 64.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.2500, 80.0000],\n",
       "         [ 0.2500, 78.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.2500, 75.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 0.5000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 64.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.2500, 80.0000],\n",
       "         [ 0.2500, 78.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 75.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 1.0000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 64.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.2500, 80.0000],\n",
       "         [ 0.2500, 78.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.2500, 78.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 75.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 0.5000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 81.0000],\n",
       "         [ 0.5000, 85.0000],\n",
       "         [ 0.5000, 83.0000],\n",
       "         [ 1.0000, 81.0000],\n",
       "         [ 1.0000, 76.0000],\n",
       "         [ 0.4000, 81.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 72.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.0000, 67.0000],\n",
       "         [ 0.4000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 72.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.0000, 67.0000],\n",
       "         [ 0.6500, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 72.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.0000, 67.0000],\n",
       "         [ 0.9000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 72.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 0.9000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 56.0000],\n",
       "         [ 0.5000, 58.0000],\n",
       "         [ 0.5000, 54.0000],\n",
       "         [ 1.0000, 56.0000],\n",
       "         [ 1.0000, 66.0000],\n",
       "         [ 0.6000, 65.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 64.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 1.0000, 57.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.6000, 73.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.2000, 64.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 1.0000, 64.0000],\n",
       "         [ 0.8000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 66.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 1.0000, 64.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.0000, 73.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 64.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 1.0000, 64.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 0.3500, 73.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 83.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 1.0000, 81.0000],\n",
       "         [ 1.0000, 79.0000],\n",
       "         [ 1.2000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 1.0000, 75.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.2000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.2000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 74.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.5000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 0.9500, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.4000, 70.0000],\n",
       "         [ 1.0000, 65.0000],\n",
       "         [ 1.0000, 62.0000],\n",
       "         [ 0.6000, 63.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.4000, 79.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 0.6000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.4000, 79.0000],\n",
       "         [ 2.0000, 74.0000],\n",
       "         [ 0.6000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 1., 74.],\n",
       "         [ 1., 71.],\n",
       "         [ 2., 72.]], dtype=torch.float64),\n",
       " tensor([[ 1.4000, 79.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 0.3500, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.6000, 80.0000],\n",
       "         [ 1.0000, 78.0000],\n",
       "         [ 0.7500, 78.0000],\n",
       "         [ 0.2500, 80.0000],\n",
       "         [ 0.4000, 82.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.6000, 69.0000],\n",
       "         [ 1.0000, 67.0000],\n",
       "         [ 0.7500, 67.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.4000, 63.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.6000, 69.0000],\n",
       "         [ 1.0000, 67.0000],\n",
       "         [ 0.7500, 67.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.4000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 67.0000],\n",
       "         [ 0.7500, 67.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 2.0000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.6000, 69.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 1.0000, 67.0000],\n",
       "         [ 0.7500, 67.0000],\n",
       "         [ 0.1500, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 79.0000],\n",
       "         [ 1.0000, 77.0000],\n",
       "         [ 1.0000, 79.0000],\n",
       "         [ 1.5000, 75.0000],\n",
       "         [ 0.3000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 78.0000],\n",
       "         [ 1.0000, 77.0000],\n",
       "         [ 1.0000, 79.0000],\n",
       "         [ 1.5000, 75.0000],\n",
       "         [ 0.3000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 79.0000],\n",
       "         [ 1.0000, 77.0000],\n",
       "         [ 1.5000, 79.0000],\n",
       "         [ 1.3000, 75.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 79.0000],\n",
       "         [ 1.0000, 79.0000],\n",
       "         [ 1.5000, 75.0000],\n",
       "         [ 1.3000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[2.0000e-01, 7.9000e+01],\n",
       "         [2.5000e-01, 7.8000e+01],\n",
       "         [1.0000e+00, 7.7000e+01],\n",
       "         [1.0000e+00, 7.9000e+01],\n",
       "         [1.5000e+00, 7.5000e+01],\n",
       "         [5.0000e-02, 7.4000e+01]], dtype=torch.float64),\n",
       " tensor([[ 1., 76.],\n",
       "         [ 1., 74.],\n",
       "         [ 1., 72.],\n",
       "         [ 1., 74.]], dtype=torch.float64),\n",
       " tensor([[ 1., 71.],\n",
       "         [ 1., 69.],\n",
       "         [ 1., 67.],\n",
       "         [ 1., 76.]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 71.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 1.0000, 67.0000],\n",
       "         [ 1.5000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 1., 71.],\n",
       "         [ 1., 67.],\n",
       "         [ 2., 69.]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 71.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 1.0000, 67.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.7500, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 72.0000],\n",
       "         [ 1.0000, 70.0000],\n",
       "         [ 2.2000, 68.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 66.0000],\n",
       "         [ 1.0000, 64.0000],\n",
       "         [ 2.2000, 65.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.2000, 66.0000],\n",
       "         [ 1.0000, 64.0000],\n",
       "         [ 1.8000, 62.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 66.0000],\n",
       "         [ 3.2000, 64.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 66.0000],\n",
       "         [ 1.0000, 64.0000],\n",
       "         [ 0.5000, 61.0000],\n",
       "         [ 1.7000, 62.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.4000, 59.0000],\n",
       "         [ 0.5000, 59.0000],\n",
       "         [ 0.5000, 57.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 60.0000],\n",
       "         [ 0.5000, 57.0000],\n",
       "         [ 0.1000, 55.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.4000, 66.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.1000, 62.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.4000, 66.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 1.5000, 69.0000],\n",
       "         [ 0.1000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.4000, 66.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.6000, 62.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.4000, 66.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.3500, 64.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 60.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 65.0000],\n",
       "         [ 0.2500, 64.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.5000, 60.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 62.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 66.0000],\n",
       "         [ 0.2500, 64.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 62.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 66.0000],\n",
       "         [ 0.2500, 64.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.3750, 69.0000],\n",
       "         [ 0.1250, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 62.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 66.0000],\n",
       "         [ 0.2500, 64.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.5000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 62.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 66.0000],\n",
       "         [ 0.2500, 64.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 86.0000],\n",
       "         [ 1.0000, 86.0000],\n",
       "         [ 2.0000, 85.0000],\n",
       "         [ 0.4000, 81.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 78.0000],\n",
       "         [ 1.0000, 77.0000],\n",
       "         [ 2.0000, 76.0000],\n",
       "         [ 0.4000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 77.0000],\n",
       "         [ 1.0000, 77.0000],\n",
       "         [ 2.0000, 76.0000],\n",
       "         [ 0.4000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 77.0000],\n",
       "         [ 1.0000, 77.0000],\n",
       "         [ 2.4000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 77.0000],\n",
       "         [ 1.0000, 77.0000],\n",
       "         [ 0.2500, 75.0000],\n",
       "         [ 2.0000, 76.0000],\n",
       "         [ 0.1500, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 60.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 1.0000, 62.0000],\n",
       "         [ 0.5000, 64.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 60.0000],\n",
       "         [ 0.3000, 59.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 72.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.3000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 72.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 0.5500, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 72.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.8000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 72.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 1.0000, 73.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.3000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 81.0000],\n",
       "         [ 0.5000, 82.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.7500, 79.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 1.0000, 81.0000],\n",
       "         [ 0.6000, 81.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 69.0000],\n",
       "         [ 0.5000, 70.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.7500, 67.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.6000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 69.0000],\n",
       "         [ 0.5000, 70.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.7500, 67.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.4000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 69.0000],\n",
       "         [ 0.5000, 70.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.7500, 67.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.8500, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 73.0000],\n",
       "         [ 0.4000, 69.0000],\n",
       "         [ 0.5000, 70.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.7500, 67.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.1000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7000, 72.0000],\n",
       "         [ 1.0000, 70.0000],\n",
       "         [ 1.0000, 75.0000],\n",
       "         [ 1.3000, 75.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7000, 71.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 1.0000, 79.0000],\n",
       "         [ 1.3000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 2.1000, 71.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.9000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7000, 71.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 2.3000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.7000, 71.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.8000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 60.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 63.0000],\n",
       "         [ 2.0000, 62.0000],\n",
       "         [ 0.9000, 58.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 71.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 2.0000, 73.0000],\n",
       "         [ 0.9000, 73.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 71.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 2.0000, 73.0000],\n",
       "         [ 0.4000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 71.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 2.0000, 73.0000],\n",
       "         [ 1.4000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.1000, 71.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 2.0000, 73.0000],\n",
       "         [ 0.4000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 64.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.5000, 73.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 62.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.5000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 62.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.5000, 72.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 62.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 0.5000, 71.0000],\n",
       "         [ 1.0000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.5000, 62.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 1.0000, 67.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 72.0000],\n",
       "         [ 0.5000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 68.0000],\n",
       "         [ 0.2500, 34.0000],\n",
       "         [ 0.2500, 65.0000],\n",
       "         [ 0.2500, 70.0000],\n",
       "         [ 0.2500, 34.0000],\n",
       "         [ 0.2500, 68.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.2500, 34.0000],\n",
       "         [ 0.2500, 65.0000],\n",
       "         [ 0.2500, 63.0000],\n",
       "         [ 0.2500, 34.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 63.0000],\n",
       "         [ 0.2500, 51.0000],\n",
       "         [ 0.2500, 60.0000],\n",
       "         [ 0.2500, 34.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 79.0000],\n",
       "         [ 0.2500, 45.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 45.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 78.0000],\n",
       "         [ 0.2500, 45.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 45.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 71.0000],\n",
       "         [ 0.2500, 47.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 79.0000],\n",
       "         [ 0.2500, 45.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.5000, 45.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 78.0000],\n",
       "         [ 0.2500, 45.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 45.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 45.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 45.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 78.0000],\n",
       "         [ 0.2500, 45.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 45.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 71.0000],\n",
       "         [ 0.5000, 45.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 79.0000],\n",
       "         [ 0.2500, 45.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 45.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 78.0000],\n",
       "         [ 0.2500, 45.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 45.0000],\n",
       "         [ 0.2500, 73.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 62.0000],\n",
       "         [ 0.2500, 71.0000]], dtype=torch.float64),\n",
       " tensor([[2.0000e-01, 6.8000e+01],\n",
       "         [7.5000e-01, 6.7000e+01],\n",
       "         [2.5000e-01, 6.5000e+01],\n",
       "         [1.0000e+00, 6.4000e+01],\n",
       "         [1.0000e+00, 6.0000e+01],\n",
       "         [7.5000e-01, 6.5000e+01],\n",
       "         [5.0000e-02, 6.7000e+01]], dtype=torch.float64),\n",
       " tensor([[2.0000e-01, 7.7000e+01],\n",
       "         [7.5000e-01, 7.6000e+01],\n",
       "         [2.5000e-01, 6.8000e+01],\n",
       "         [1.0000e+00, 7.3000e+01],\n",
       "         [1.0000e+00, 6.9000e+01],\n",
       "         [7.5000e-01, 7.4000e+01],\n",
       "         [5.0000e-02, 7.6000e+01]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 77.0000],\n",
       "         [ 0.7500, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 2.0000, 73.0000],\n",
       "         [ 0.8000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 77.0000],\n",
       "         [ 0.7500, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 1.0000, 73.0000],\n",
       "         [ 0.7500, 74.0000],\n",
       "         [ 1.0500, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 77.0000],\n",
       "         [ 0.7500, 76.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 1.0000, 73.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.8000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 56.0000],\n",
       "         [ 2.0000, 58.0000],\n",
       "         [ 1.0000, 63.0000],\n",
       "         [ 0.8000, 63.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 67.0000],\n",
       "         [ 2.0000, 69.0000],\n",
       "         [ 1.0000, 66.0000],\n",
       "         [ 0.8000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 67.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.8000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 67.0000],\n",
       "         [ 2.0000, 69.0000],\n",
       "         [ 1.8000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 67.0000],\n",
       "         [ 2.0000, 69.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.3000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 2., 75.],\n",
       "         [ 1., 70.],\n",
       "         [ 1., 67.]], dtype=torch.float64),\n",
       " tensor([[ 2., 77.],\n",
       "         [ 1., 72.],\n",
       "         [ 1., 65.]], dtype=torch.float64),\n",
       " tensor([[ 2.0000, 77.0000],\n",
       "         [ 1.5000, 72.0000],\n",
       "         [ 0.5000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 2., 77.],\n",
       "         [ 2., 72.]], dtype=torch.float64),\n",
       " tensor([[ 2.0000, 77.0000],\n",
       "         [ 0.2500, 68.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 0.7500, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 59.0000],\n",
       "         [ 0.5000, 59.0000],\n",
       "         [ 0.2500, 64.0000],\n",
       "         [ 0.2500, 66.0000],\n",
       "         [ 0.2500, 68.0000],\n",
       "         [ 0.2500, 64.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.5000, 59.0000],\n",
       "         [ 0.2500, 64.0000],\n",
       "         [ 0.2500, 66.0000],\n",
       "         [ 0.2500, 68.0000],\n",
       "         [ 0.2500, 64.0000],\n",
       "         [ 0.2000, 66.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 83.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 83.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2000, 81.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.1250, 83.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 83.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.3250, 81.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 83.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 83.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.7000, 81.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 83.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.2500, 83.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.8000, 90.0000],\n",
       "         [ 1.0000, 85.0000],\n",
       "         [ 1.2000, 87.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.8000, 79.0000],\n",
       "         [ 1.0000, 71.0000],\n",
       "         [ 1.2000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.8000, 79.0000],\n",
       "         [ 2.0000, 74.0000],\n",
       "         [ 0.2000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 1., 74.],\n",
       "         [ 3., 76.]], dtype=torch.float64),\n",
       " tensor([[ 1.8000, 79.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.7000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 75.0000],\n",
       "         [ 1.0000, 73.0000],\n",
       "         [ 1.0000, 73.0000],\n",
       "         [ 1.2000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 75.0000],\n",
       "         [ 1.0000, 73.0000],\n",
       "         [ 1.0000, 73.0000],\n",
       "         [ 1.2000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.2000, 75.0000],\n",
       "         [ 1.0000, 73.0000],\n",
       "         [ 1.0000, 73.0000],\n",
       "         [ 0.8000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 75.0000],\n",
       "         [ 1.0000, 73.0000],\n",
       "         [ 2.2000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 75.0000],\n",
       "         [ 1.0000, 73.0000],\n",
       "         [ 1.0000, 73.0000],\n",
       "         [ 1.0000, 73.0000],\n",
       "         [ 0.2000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 76.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.3330, 83.0000],\n",
       "         [ 0.3330, 83.0000],\n",
       "         [ 0.3330, 83.0000],\n",
       "         [ 1.0000, 81.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 0.2010, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 64.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.3330, 75.0000],\n",
       "         [ 0.3330, 71.0000],\n",
       "         [ 0.3330, 71.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.2010, 64.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 64.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.1665, 71.0000],\n",
       "         [ 0.3330, 71.0000],\n",
       "         [ 0.3330, 71.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.3675, 64.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 64.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.3330, 71.0000],\n",
       "         [ 0.3330, 71.0000],\n",
       "         [ 0.3330, 71.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 1.2010, 64.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 64.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.2500, 60.0000],\n",
       "         [ 0.5000, 62.0000],\n",
       "         [ 0.3330, 71.0000],\n",
       "         [ 0.3330, 71.0000],\n",
       "         [ 0.3330, 71.0000],\n",
       "         [ 1.0000, 69.0000],\n",
       "         [ 0.4510, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.5000, 77.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 2.0000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.5000, 77.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 2.0000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.5000, 77.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 2.0000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.5000, 77.0000],\n",
       "         [ 2.5000, 79.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.5000, 77.0000],\n",
       "         [ 1.0000, 82.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 1.0000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 85.0000],\n",
       "         [ 1.0000, 86.0000],\n",
       "         [ 1.0000, 83.0000],\n",
       "         [ 1.0000, 85.0000],\n",
       "         [ 0.8000, 86.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 74.0000],\n",
       "         [ 1.0000, 82.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.8000, 75.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 74.0000],\n",
       "         [ 1.0000, 75.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.4000, 75.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 74.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.8000, 75.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2000, 74.0000],\n",
       "         [ 1.0000, 75.0000],\n",
       "         [ 1.0000, 72.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.5500, 75.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6500, 52.0000],\n",
       "         [ 0.2500, 54.0000],\n",
       "         [ 3.0000, 54.0000],\n",
       "         [ 0.1000, 59.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6500, 74.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 3.0000, 69.0000],\n",
       "         [ 0.1000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6500, 67.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 3.1000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6500, 67.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 3.1000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6500, 67.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 3.0000, 69.0000],\n",
       "         [ 0.1000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 76.0000],\n",
       "         [ 2.0000, 78.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.6000, 83.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 69.0000],\n",
       "         [ 2.0000, 71.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.6000, 80.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 69.0000],\n",
       "         [ 2.0000, 71.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.4000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 69.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 2.6000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.2500, 73.0000],\n",
       "         [ 0.4000, 69.0000],\n",
       "         [ 2.0000, 71.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.3500, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 60.0000],\n",
       "         [ 1.5000, 60.0000],\n",
       "         [ 1.0000, 63.0000],\n",
       "         [ 1.2000, 61.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 71.0000],\n",
       "         [ 1.5000, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.2000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 71.0000],\n",
       "         [ 1.5000, 71.0000],\n",
       "         [ 2.2000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.5000, 71.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.5000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 71.0000],\n",
       "         [ 1.0000, 68.0000],\n",
       "         [ 1.5000, 71.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 0.2000, 72.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 74.0000],\n",
       "         [ 0.5000, 69.0000],\n",
       "         [ 0.2500, 74.0000],\n",
       "         [ 0.2500, 76.0000],\n",
       "         [ 0.5000, 77.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 73.0000],\n",
       "         [ 0.7000, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 79.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.5000, 82.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 0.7000, 79.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 79.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.5000, 82.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 0.2500, 78.0000],\n",
       "         [ 0.9500, 79.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 79.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 1.2000, 79.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.3000, 79.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.2500, 79.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.5000, 82.0000],\n",
       "         [ 0.2500, 81.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 0.4500, 79.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 73.0000],\n",
       "         [ 1.0000, 73.0000],\n",
       "         [ 2.0000, 78.0000],\n",
       "         [ 0.4000, 70.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 68.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 2.0000, 79.0000],\n",
       "         [ 0.4000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 74.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.0000, 79.0000],\n",
       "         [ 1.4000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 74.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 2.4000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 74.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 2.0000, 79.0000],\n",
       "         [ 0.4000, 68.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 83.0000],\n",
       "         [ 0.5000, 82.0000],\n",
       "         [ 0.5000, 75.0000],\n",
       "         [ 0.2500, 80.0000],\n",
       "         [ 0.2500, 78.0000],\n",
       "         [ 0.2500, 77.0000],\n",
       "         [ 0.2500, 75.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 75.0000],\n",
       "         [ 0.6000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 75.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 0.2500, 70.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.6000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 75.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 0.2500, 70.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.7500, 67.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.1000, 69.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.4000, 75.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 0.2500, 70.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 1.1000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 1.0000, 77.0000],\n",
       "         [ 0.4000, 75.0000],\n",
       "         [ 0.5000, 74.0000],\n",
       "         [ 0.5000, 67.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 0.2500, 70.0000],\n",
       "         [ 0.2500, 69.0000],\n",
       "         [ 0.2500, 67.0000],\n",
       "         [ 0.5000, 66.0000],\n",
       "         [ 0.1000, 67.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 91.0000],\n",
       "         [ 2.0000, 91.0000],\n",
       "         [ 1.0000, 88.0000],\n",
       "         [ 0.4000, 86.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 79.0000],\n",
       "         [ 2.0000, 79.0000],\n",
       "         [ 1.0000, 76.0000],\n",
       "         [ 0.4000, 79.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 79.0000],\n",
       "         [ 2.0000, 79.0000],\n",
       "         [ 1.4000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 79.0000],\n",
       "         [ 2.0000, 79.0000],\n",
       "         [ 1.4000, 76.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.6000, 79.0000],\n",
       "         [ 2.0000, 79.0000],\n",
       "         [ 0.2500, 71.0000],\n",
       "         [ 1.0000, 76.0000],\n",
       "         [ 0.1500, 74.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 94.0000],\n",
       "         [ 0.5000, 89.0000],\n",
       "         [ 0.5000, 91.0000],\n",
       "         [ 0.5000, 92.0000],\n",
       "         [ 0.5000, 94.0000],\n",
       "         [ 1.2000, 91.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 81.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 1.2000, 78.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 81.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.7500, 78.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.9500, 78.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 81.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 1.7000, 81.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 81.0000],\n",
       "         [ 0.5000, 76.0000],\n",
       "         [ 0.5000, 78.0000],\n",
       "         [ 0.5000, 79.0000],\n",
       "         [ 0.5000, 81.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 0.9500, 78.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 78.0000],\n",
       "         [ 1.0000, 80.0000],\n",
       "         [ 2.2000, 77.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 2.2000, 68.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 72.0000],\n",
       "         [ 1.5000, 74.0000],\n",
       "         [ 1.7000, 71.0000]], dtype=torch.float64),\n",
       " tensor([[ 1., 74.],\n",
       "         [ 3., 71.]], dtype=torch.float64),\n",
       " tensor([[ 0.8000, 72.0000],\n",
       "         [ 0.2500, 72.0000],\n",
       "         [ 1.0000, 74.0000],\n",
       "         [ 1.9500, 71.0000]], dtype=torch.float64)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cunn2\\AppData\\Local\\Temp\\ipykernel_179896\\1221544938.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  encoder.load_state_dict(torch.load(\"sms/exp1/runs/run_20240926_162652/pretrain_saved_model.pth\"))\n"
     ]
    }
   ],
   "source": [
    "cfg = load_config_from_launchplan(\"sms/exp1/runs/run_20240926_162652/original_launchplan.yaml\")\n",
    "encoder = build_encoder(cfg.model_dump())\n",
    "encoder.load_state_dict(torch.load(\"sms/exp1/runs/run_20240926_162652/pretrain_saved_model.pth\"))\n",
    "\n",
    "embeddings_dict = create_embedding_dicts(data_dict, cfg.model_dump(), encoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/integrations/vectorstores/faiss/#similarity-search-with-filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from sms.exp1.config_classes import LaunchPlanConfig\n",
    "\n",
    "class ModelEvalConfig(BaseModel):\n",
    "    name: str\n",
    "    lp_config: LaunchPlanConfig\n",
    "    mod_path: str\n",
    "    path_type: str    #'full' or 'encoder'\n",
    "    use_full_model: bool\n",
    "\n",
    "def run_evaluation(\n",
    "    data_dict: Dict[str, np.ndarray],\n",
    "    num_loops: int,\n",
    "    model_configs: List[ModelEvalConfig]\n",
    "    ) -> Dict[str, Dict[str, Dict[str, Dict[str, List[float]]]]]:\n",
    "\n",
    "    # generate random augmentations\n",
    "    anchor_keys = np.random.choice(list(data_dict.keys()), size=num_loops, replace=False)\n",
    "    augmented_data = create_augmented_data(data_dict, anchor_keys)\n",
    "\n",
    "    results = {}\n",
    "    for eval_config in model_configs:\n",
    "        logger.info(f\"Running evaluation for {eval_config.name}\")\n",
    "\n",
    "        dumped_lp_config = eval_config.lp_config.model_dump()\n",
    "        bm_cfg = {'full_model_path': eval_config.mod_path} if eval_config.path_type == 'full' else {'encoder_path': eval_config.mod_path}\n",
    "\n",
    "        model = build_model(dumped_lp_config, **bm_cfg, use_full_model=eval_config.use_full_model)\n",
    "        embeddings_dict = create_embedding_dict(data_dict, dumped_lp_config, model)\n",
    "\n",
    "        # create augmented embeddings structure\n",
    "        augmented_embeddings_dict = {}\n",
    "        for data_id, aug_dict in augmented_data.items():\n",
    "            augmented_embeddings_dict[data_id] = create_embedding_dict(aug_dict, dumped_lp_config, model)\n",
    "\n",
    "        dim = list(embeddings_dict.values())[0].shape[0]\n",
    "        index = embeddings_to_faiss_index(embeddings_dict=embeddings_dict, index_type=\"IndexFlatL2\", index_args=[dim])\n",
    "\n",
    "        results[eval_config.name] = evaluate_top_k(embeddings_dict, augmented_embeddings_dict, [1, 3, 5, 10, 25, 50, 100], index)\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_ids = [str(uuid4()) for _ in range(len(filtered_data))]\n",
    "filtered_data_dict = dict(zip(filtered_data_ids, filtered_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 12 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by -5 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 2 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 0 with duration 0.25 and relative pitch -3.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -5 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 3 by 4 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 6 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 6 by 0.20000000000000018 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 0 with duration 0.25 and relative pitch -4.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 7 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 6 by 0.04999999999999999 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 8 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 0 by -1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 2 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.20000000000000018 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 1 with duration 0.25 and relative pitch -6.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 9 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 3 by 5 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 7 by a factor of 1.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 8 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 7 by 0.15 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [6].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 0 with duration 1.0 and relative pitch 4.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 9 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 8 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 7 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 6 by 0.15000000000000002 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 2 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 2 by -8 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 2 by a factor of 1.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 3 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 2 by 0.45 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.20000000000000018 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 2 with duration 0.5 and relative pitch -5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 4 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.2 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -10 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 0 by -1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 3 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 5 with duration 0.8 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 4 with duration 1.0 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.19999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [5].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.7999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 0.25 and relative pitch 5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 6 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -9 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 5 by -5 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 10 by a factor of 1.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 12 by 0.125 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 11 with duration 0.25 and relative pitch -3.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 13 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 5 by -2 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 3 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 5 with duration 0.25 and relative pitch 0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 7 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 0 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 0 by -3 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 3 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 2.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 0.25 and relative pitch -3.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -9 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by -7 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 4 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 6 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [5].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 1 with duration 1.0 and relative pitch 3.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 7 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 6 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 12 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 4 by -8 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 8 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 11 with duration 0.05 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 10 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 9 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 8 by 0.44999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 9 with duration 0.5 and relative pitch -6.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 12 with duration 0.05 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 11 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 10 by 0.2 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 14 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by 1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 0 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 0 with duration 0.25 and relative pitch 4.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 8 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 3 by 6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 9 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 11 with duration 0.05 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 10 by 0.2 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [7].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 11 with duration 0.5 and relative pitch -3.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 12 with duration 0.05 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 11 by 0.45 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -10 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 4 by -4 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 4 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.9000000000000004 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 0.25 and relative pitch -6.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -15 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by -4 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 0 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 5 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.75 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [5].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 4 with duration 1.0 and relative pitch -3.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 6 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.75 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -11 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 12 by -7 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 0 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 14 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 13 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [13].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 10 with duration 0.5 and relative pitch 3.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 15 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 14 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 5 by 7 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 4 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [7].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.20000000000000018 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 0.5 and relative pitch 0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 8 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 7 by 0.3 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -5 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 2 by 3 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 2 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 3 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 2 by 0.2 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.20000000000000018 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 0.5 and relative pitch -4.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 4 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.2 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 12 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 8 by -7 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 6 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 8 with duration 0.1009999999999999 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 7 by 0.2319999999999994 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 0.5 and relative pitch -6.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 9 with duration 0.1009999999999999 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 8 by 0.39900000000000013 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 4 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 7 by 1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 7 by a factor of 1.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 9 by 0.125 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 0 with duration 0.25 and relative pitch 0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 10 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 5 by 3 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 2 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.375 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.4 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 6 with duration 0.25 and relative pitch -2.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 7 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 6 by 0.15 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by -1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 6 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 7 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 6 by 0.9 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [6].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 7 with duration 0.25 and relative pitch -6.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 8 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 7 by 0.15 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 14 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 2 by 6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 5 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.20000000000000018 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 0 with duration 0.25 and relative pitch -1.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 6 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.04999999999999999 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 12 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by 2 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 2 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 2 by 1.1999999999999993 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.2000000000000002 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 2 with duration 0.25 and relative pitch -2.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 12 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 5 by -7 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 2 by a factor of 1.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 9 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 4 with duration 1.0 and relative pitch -5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 10 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 9 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 8 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 8 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 6 by 4 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 6 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.19999999999999973 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 6 with duration 0.5 and relative pitch 5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 7 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 6 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -10 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 0 by 0 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 0 by a factor of 1.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.2999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 1 with duration 0.5 and relative pitch 0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 6 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 14 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 0 by -5 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 5 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 6 with duration 0.25 and relative pitch -4.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 7 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -8 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 6 by -2 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 0 by a factor of 1.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 7 by 0.04999999999999982 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [5].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.75 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 0 with duration 0.5 and relative pitch 3.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 8 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 7 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -15 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 2 by 2 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 6 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 9 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 8 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 7 by 0.4 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.3999999999999999 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 6 with duration 0.25 and relative pitch 2.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 10 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 9 by 0.15 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 3 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by 1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 2 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 2 by 2.2 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 2.2 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 2 with duration 0.5 and relative pitch 5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -13 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 4 by 0 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 4 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 5 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 4 with duration 0.5 and relative pitch 1.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 6 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 3 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 7 by -7 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 6 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 7 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 6 by 0.3 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [6].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 0 with duration 0.5 and relative pitch 4.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 8 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 7 by 0.3 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 5 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by -6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 3 by a factor of 1.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.20000000000000018 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.3999999999999999 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 0 with duration 0.5 and relative pitch 2.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 4 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 13 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by -6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 1 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.7999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 2 with duration 0.5 and relative pitch 2.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -5 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 5 by -2 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 8 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 9 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 8 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 8 with duration 0.25 and relative pitch 5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 10 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 5 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by 6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 3 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 6 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.4 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 2 with duration 0.25 and relative pitch 0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 7 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 6 by 0.15 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -3 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 4 by -1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 1 by a factor of 1.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 6 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 6 with duration 0.25 and relative pitch 5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 7 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 12 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 2 by -1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 0 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 4 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 3 with duration 1.0 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 2 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 1 by 0.19999999999999973 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 1 with duration 1.0 and relative pitch 3.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 5 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.9 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 3 by 4 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 0 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 4 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.8000000000000002 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 0.5 and relative pitch -3.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 5 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -15 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 2 by 1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 8 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.125 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 0 with duration 1.0 and relative pitch 1.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 13 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 12 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 11 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 10 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 9 by 0.050000000000000044 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 13 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 11 by -4 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 5 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 11 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [10].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 1 with duration 0.5 and relative pitch 0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 12 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 3 by -3 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 0 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 4 with duration 0.6 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.19999999999999984 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 1 with duration 1.0 and relative pitch 1.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 5 with duration 0.6 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.4 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 2 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 0 by -6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 2 by a factor of 1.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 3 with duration 0.8 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 2 by 0.19999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 2.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 0 with duration 0.5 and relative pitch -2.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 9 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 2 by -3 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 2 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 3 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 2 by 1.6 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.6000000000000001 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 0 with duration 1.0 and relative pitch 3.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 4 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.6 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -13 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 4 by -4 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 2 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 4 with duration 0.25 and relative pitch -3.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 10 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 2 by 0 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 3 by a factor of 1.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 4 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.15 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.3999999999999999 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 0 with duration 0.5 and relative pitch 2.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 5 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.4 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -15 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 4 by -5 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 3 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 8 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 6 with duration 0.25 and relative pitch 0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 9 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 4 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 4 by -3 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 10 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.1499999999999999 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [7].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 8 with duration 0.5 and relative pitch -4.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 11 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 10 by 0.2 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by -5 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 2 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.0999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 2.2 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 1 with duration 1.0 and relative pitch -1.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 11 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 0 by 3 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 3 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.2999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.2999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 1 with duration 0.25 and relative pitch 5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -7 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 0 by 4 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 2 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 7 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 6 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [7].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.3999999999999999 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 2 with duration 0.5 and relative pitch 5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 8 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 7 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 2 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 3 by -6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 3 by a factor of 1.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.09999999999999964 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 2.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 0.25 and relative pitch 2.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 4 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.04999999999999999 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 2 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 6 by 4 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 7 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.125 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [6].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 6 with duration 0.25 and relative pitch 4.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 9 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -9 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 2 by -6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 0 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.15000000000000036 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [8].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.7009999999999996 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 2 with duration 1.0 and relative pitch 0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 9 with duration 0.7009999999999994 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 8 by 0.2989999999999997 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -10 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 2 by 3 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 3 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 0 with duration 1.0 and relative pitch 5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 4 with duration 1.0 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -9 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by -6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 3 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 5 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 4 with duration 1.0 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 1.7000000000000002 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 0.5 and relative pitch 0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 6 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.2 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 9 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 7 by -4 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 8 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 9 with duration 0.5 and relative pitch -4.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 12 with duration 0.05 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 11 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 10 by 0.2 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -16 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 5 by -7 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 0 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.40000000000000036 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 1.0 and relative pitch 2.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 8 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 7 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 6 by 0.55 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 12 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by -5 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 7 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 7 by 0.40000000000000036 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.75 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 0.5 and relative pitch -6.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 8 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 7 by 0.3 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -11 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 3 by 7 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 3 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 7 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [6].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 0 with duration 0.5 and relative pitch -3.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 8 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -3 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 0 by 7 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 1 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 4 with duration 0.25 and relative pitch -3.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 11 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 2 by 6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 0 by a factor of 1.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.2999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 2.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 2 with duration 0.25 and relative pitch 2.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -5 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by -8 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 0 by a factor of 1.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 2 by 0.09999999999999964 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.7999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 2 with duration 0.5 and relative pitch -6.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 9 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 2 by -2 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 0 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.40000000000000036 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.20000000000000018 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 1 with duration 1.0 and relative pitch 1.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 4 with duration 0.8 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.19999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 14 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 4 by -8 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 2 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 1.0 and relative pitch 1.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 5 with duration 1.0 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 15 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 4 by 3 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 5 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 1.0 and relative pitch -1.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 6 with duration 1.0 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 0 by -8 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 1 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 2 with duration 1.0 and relative pitch -2.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 3 with duration 1.0 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 13 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 5 by -8 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 3 by a factor of 1.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 7 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 6 by 0.2 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 4 with duration 1.0 and relative pitch 5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 8 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 7 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 6 by 0.19999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -8 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by -8 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 4 by a factor of 1.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 4 with duration 1.0 and relative pitch -5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 6 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 5 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.19999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -12 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 2 by -3 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 2 by a factor of 1.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 4 with duration 0.25 and relative pitch 2.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 13 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 0 by 6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 1 by a factor of 1.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 5 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [5].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 0 with duration 1.0 and relative pitch -2.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 6 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 5 with duration 0.75 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 2 by 6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 2 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.375 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [6].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.1499999999999999 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 1 with duration 0.5 and relative pitch -5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 7 with duration 0.15 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 6 by 0.35 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -14 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 7 by -7 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 4 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 7 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [7].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.7999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 0 with duration 1.0 and relative pitch -2.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 8 with duration 0.8 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 7 by 0.19999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 0 by 7 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 6 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 6 by 0.5999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 2 with duration 1.0 and relative pitch 0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 7 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 6 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.19999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -8 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by 5 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 1 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.7999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 2 with duration 0.25 and relative pitch 4.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 15 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by 6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 3 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.19999999999999973 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 0.25 and relative pitch 0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -9 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 6 by -6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 7 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 10 with duration 0.075 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 9 by 0.05 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [9].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.125 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 8 with duration 0.25 and relative pitch 2.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 11 with duration 0.075 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 10 with duration 0.125 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 9 by 0.04999999999999999 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 10 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 5 by -4 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 7 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 7 by 0.09999999999999964 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [6].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 1.0 and relative pitch 4.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 8 with duration 0.1 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 7 by 0.9 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 14 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 6 by -4 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 2 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 6 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.3 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 6 with duration 1.0 and relative pitch 3.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 7 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 6 by 0.8 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by 5 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 4 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 5 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.6 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 0 with duration 0.5 and relative pitch -2.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 6 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 9 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by 2 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 8 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 8 by 0.2999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.75 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 7 with duration 0.5 and relative pitch -6.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 9 with duration 0.15 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 8 by 0.35 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 2 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 3 by 3 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 4 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.125 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.75 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 0.25 and relative pitch -5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 9 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 3 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 1 by 6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 1 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 3 with duration 0.8 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 2 by 0.19999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 2.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 0.5 and relative pitch -2.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 0 by -2 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 4 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.20000000000000018 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.20000000000000018 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 2 with duration 1.0 and relative pitch 0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 5 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.8 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -4 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 4 by -6 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 0 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 4 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 3 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.75 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 0.5 and relative pitch -5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 5 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 12 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 2 by -1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 0 by a factor of 1.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.09999999999999964 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.2999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 0.25 and relative pitch 5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 5 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 13 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 4 by 1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 1 by a factor of 2.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 4 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 0.8 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 0 with duration 0.5 and relative pitch 5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 5 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 4 by 0.3 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by 4 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 7 by 3 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 6 by a factor of 0.5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.125 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [5].\n",
      "[2024-09-29 15:21:04] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Inserting note at index 3 with duration 0.25 and relative pitch 5.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 11 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Transposing non-rest notes by -1 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Shifting note at index 4 by 5 semitones.\n",
      "[2024-09-29 15:21:04] [DEBUG] Scaling duration of note at index 0 by a factor of 3.0.\n",
      "[2024-09-29 15:21:04] [DEBUG] Removed note 4 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Truncated note 3 by 1.0999999999999994 to maintain total duration.\n",
      "[2024-09-29 15:21:04] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:21:05] [DEBUG] Elongated last note by 0.2999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Inserting note at index 3 with duration 1.0 and relative pitch 0.\n",
      "[2024-09-29 15:21:05] [DEBUG] Removed note 5 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Truncated note 4 by 0.7 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Transposing non-rest notes by -1 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Shifting note at index 2 by 5 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Scaling duration of note at index 0 by a factor of 0.5.\n",
      "[2024-09-29 15:21:05] [DEBUG] Elongated last note by 0.6999999999999997 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:21:05] [DEBUG] Elongated last note by 1.4 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Inserting note at index 3 with duration 1.0 and relative pitch 5.\n",
      "[2024-09-29 15:21:05] [DEBUG] Removed note 4 with duration 0.6 to adjust total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Truncated note 3 by 0.4 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Transposing non-rest notes by -2 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Shifting note at index 0 by 7 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Scaling duration of note at index 5 by a factor of 1.5.\n",
      "[2024-09-29 15:21:05] [DEBUG] Removed note 6 with duration 0.4 to adjust total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Truncated note 5 by 0.09999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:21:05] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Inserting note at index 1 with duration 0.25 and relative pitch -6.\n",
      "[2024-09-29 15:21:05] [DEBUG] Truncated note 7 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Transposing non-rest notes by 9 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Shifting note at index 2 by 3 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Scaling duration of note at index 4 by a factor of 2.0.\n",
      "[2024-09-29 15:21:05] [DEBUG] Truncated note 6 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Deleting notes at indices [3].\n",
      "[2024-09-29 15:21:05] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Inserting note at index 0 with duration 0.5 and relative pitch -1.\n",
      "[2024-09-29 15:21:05] [DEBUG] Truncated note 7 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Transposing non-rest notes by -4 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Shifting note at index 2 by 0 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Scaling duration of note at index 6 by a factor of 3.0.\n",
      "[2024-09-29 15:21:05] [DEBUG] Truncated note 6 by 0.40000000000000036 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Deleting notes at indices [0].\n",
      "[2024-09-29 15:21:05] [DEBUG] Elongated last note by 0.7999999999999998 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Inserting note at index 1 with duration 1.0 and relative pitch -4.\n",
      "[2024-09-29 15:21:05] [DEBUG] Removed note 7 with duration 0.2 to adjust total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Removed note 6 with duration 0.25 to adjust total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Truncated note 5 by 0.55 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Transposing non-rest notes by -10 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Shifting note at index 7 by -8 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Scaling duration of note at index 6 by a factor of 0.5.\n",
      "[2024-09-29 15:21:05] [DEBUG] Elongated last note by 0.0625 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Deleting notes at indices [6].\n",
      "[2024-09-29 15:21:05] [DEBUG] Elongated last note by 0.125 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Inserting note at index 4 with duration 0.25 and relative pitch 1.\n",
      "[2024-09-29 15:21:05] [DEBUG] Truncated note 8 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Transposing non-rest notes by 9 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Shifting note at index 0 by -2 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Scaling duration of note at index 1 by a factor of 3.0.\n",
      "[2024-09-29 15:21:05] [DEBUG] Truncated note 2 by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:21:05] [DEBUG] Elongated last note by 3.0 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Inserting note at index 1 with duration 0.25 and relative pitch -1.\n",
      "[2024-09-29 15:21:05] [DEBUG] Truncated note 3 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Transposing non-rest notes by 7 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Shifting note at index 2 by -6 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Scaling duration of note at index 0 by a factor of 0.5.\n",
      "[2024-09-29 15:21:05] [DEBUG] Elongated last note by 0.3500000000000001 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:21:05] [DEBUG] Elongated last note by 2.3 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Inserting note at index 1 with duration 1.0 and relative pitch 3.\n",
      "[2024-09-29 15:21:05] [DEBUG] Truncated note 3 by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Transposing non-rest notes by 10 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Shifting note at index 2 by 1 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Scaling duration of note at index 4 by a factor of 2.0.\n",
      "[2024-09-29 15:21:05] [DEBUG] Removed note 5 with duration 0.7 to adjust total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Truncated note 4 by 0.30000000000000004 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Deleting notes at indices [2].\n",
      "[2024-09-29 15:21:05] [DEBUG] Elongated last note by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Inserting note at index 4 with duration 0.25 and relative pitch -4.\n",
      "[2024-09-29 15:21:05] [DEBUG] Truncated note 6 by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Transposing non-rest notes by 7 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Shifting note at index 0 by -5 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Scaling duration of note at index 0 by a factor of 0.5.\n",
      "[2024-09-29 15:21:05] [DEBUG] Elongated last note by 0.09999999999999964 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Deleting notes at indices [1].\n",
      "[2024-09-29 15:21:05] [DEBUG] Elongated last note by 1.0 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Inserting note at index 4 with duration 0.5 and relative pitch 3.\n",
      "[2024-09-29 15:21:05] [DEBUG] Truncated note 5 by 0.5 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Transposing non-rest notes by 3 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Shifting note at index 2 by 4 semitones.\n",
      "[2024-09-29 15:21:05] [DEBUG] Scaling duration of note at index 1 by a factor of 3.0.\n",
      "[2024-09-29 15:21:05] [DEBUG] Removed note 8 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Truncated note 7 by 0.2 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Deleting notes at indices [4].\n",
      "[2024-09-29 15:21:05] [DEBUG] Elongated last note by 0.25 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Inserting note at index 0 with duration 1.0 and relative pitch 4.\n",
      "[2024-09-29 15:21:05] [DEBUG] Removed note 9 with duration 0.3 to adjust total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Removed note 8 with duration 0.5 to adjust total duration.\n",
      "[2024-09-29 15:21:05] [DEBUG] Truncated note 7 by 0.19999999999999996 to maintain total duration.\n",
      "[2024-09-29 15:21:05] [INFO ] Running evaluation for conv_encoder\n",
      "C:\\Users\\cunn2\\AppData\\Local\\Temp\\ipykernel_181064\\3994710600.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(encoder_path))\n"
     ]
    }
   ],
   "source": [
    "conv_eval_cfg = ModelEvalConfig(\n",
    "    name=\"conv_encoder\",\n",
    "    lp_config=load_config_from_launchplan(\"sms/exp1/runs/run_20240926_162652/original_launchplan.yaml\"),\n",
    "    mod_path=\"sms/exp1/runs/run_20240926_162652/pretrain_saved_model.pth\",\n",
    "    path_type='encoder',\n",
    "    use_full_model=False\n",
    ")\n",
    "\n",
    "configure_logging(console_level=logging.INFO)\n",
    "results = run_evaluation(filtered_data_dict, 100, [conv_eval_cfg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_encoder:\n",
      "  chunk_transposed:\n",
      "    1:\n",
      "      precision: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "      recall: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "      avg_precision: 0.0000\n",
      "      avg_recall: 0.0000\n",
      "    3:\n",
      "      precision: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "      recall: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "      avg_precision: 0.0000\n",
      "      avg_recall: 0.0000\n",
      "    5:\n",
      "      precision: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "      recall: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "      avg_precision: 0.0000\n",
      "      avg_recall: 0.0000\n",
      "    10:\n",
      "      precision: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "      recall: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "      avg_precision: 0.0000\n",
      "      avg_recall: 0.0000\n",
      "    25:\n",
      "      precision: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "      recall: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "      avg_precision: 0.0000\n",
      "      avg_recall: 0.0000\n",
      "    50:\n",
      "      precision: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "      recall: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "      avg_precision: 0.0004\n",
      "      avg_recall: 0.0200\n",
      "    100:\n",
      "      precision: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "      recall: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "      avg_precision: 0.0002\n",
      "      avg_recall: 0.0200\n",
      "  chunk_one_pitch_shifted:\n",
      "    1:\n",
      "      precision: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "      recall: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
      "      avg_precision: 0.1700\n",
      "      avg_recall: 0.1700\n",
      "    3:\n",
      "      precision: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0]\n",
      "      recall: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0]\n",
      "      avg_precision: 0.0767\n",
      "      avg_recall: 0.2300\n",
      "    5:\n",
      "      precision: [0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.0, 0.2, 0.0, 0.2, 0.0, 0.2, 0.0, 0.2, 0.0, 0.0, 0.0, 0.2, 0.0, 0.2, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.2, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.2, 0.0, 0.0, 0.0, 0.2, 0.2, 0.0, 0.0, 0.2, 0.0, 0.2]\n",
      "      recall: [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1]\n",
      "      avg_precision: 0.0560\n",
      "      avg_recall: 0.2800\n",
      "    10:\n",
      "      precision: [0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.1, 0.0, 0.1, 0.1, 0.1, 0.0, 0.1, 0.0, 0.0, 0.0, 0.1, 0.0, 0.1, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.1, 0.0, 0.1, 0.1, 0.0, 0.0, 0.0, 0.1, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.1, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0, 0.1, 0.0, 0.1]\n",
      "      recall: [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1]\n",
      "      avg_precision: 0.0340\n",
      "      avg_recall: 0.3400\n",
      "    25:\n",
      "      precision: [0.04, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04, 0.04, 0.0, 0.04, 0.0, 0.04, 0.04, 0.04, 0.0, 0.04, 0.0, 0.04, 0.0, 0.04, 0.0, 0.04, 0.04, 0.0, 0.04, 0.04, 0.0, 0.0, 0.0, 0.0, 0.04, 0.0, 0.04, 0.04, 0.04, 0.04, 0.0, 0.0, 0.0, 0.04, 0.04, 0.04, 0.0, 0.0, 0.04, 0.0, 0.04, 0.04, 0.0, 0.0, 0.04, 0.04, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04, 0.0, 0.04, 0.0, 0.04, 0.04, 0.0, 0.0, 0.0, 0.0, 0.04, 0.04, 0.0, 0.0, 0.04, 0.0, 0.0, 0.0, 0.04, 0.04, 0.0, 0.04, 0.0, 0.0, 0.04, 0.04, 0.04, 0.0, 0.0, 0.04, 0.0, 0.04]\n",
      "      recall: [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1]\n",
      "      avg_precision: 0.0180\n",
      "      avg_recall: 0.4500\n",
      "    50:\n",
      "      precision: [0.02, 0.02, 0.0, 0.0, 0.0, 0.02, 0.0, 0.02, 0.0, 0.02, 0.0, 0.0, 0.02, 0.02, 0.02, 0.0, 0.02, 0.0, 0.02, 0.02, 0.02, 0.0, 0.02, 0.0, 0.02, 0.0, 0.02, 0.0, 0.02, 0.02, 0.0, 0.02, 0.02, 0.0, 0.0, 0.0, 0.0, 0.02, 0.0, 0.02, 0.02, 0.02, 0.02, 0.0, 0.0, 0.0, 0.02, 0.02, 0.02, 0.0, 0.0, 0.02, 0.0, 0.02, 0.02, 0.0, 0.0, 0.02, 0.02, 0.02, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02, 0.0, 0.02, 0.0, 0.02, 0.02, 0.0, 0.0, 0.0, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.0, 0.0, 0.02, 0.02, 0.0, 0.02, 0.02, 0.0, 0.02, 0.02, 0.02, 0.0, 0.0, 0.02, 0.0, 0.02]\n",
      "      recall: [1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1]\n",
      "      avg_precision: 0.0108\n",
      "      avg_recall: 0.5400\n",
      "    100:\n",
      "      precision: [0.01, 0.01, 0.0, 0.01, 0.0, 0.01, 0.01, 0.01, 0.0, 0.01, 0.01, 0.0, 0.01, 0.01, 0.01, 0.0, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.01, 0.0, 0.01, 0.0, 0.01, 0.01, 0.0, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.01, 0.01, 0.01, 0.0, 0.01, 0.01, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.0, 0.01, 0.0, 0.01]\n",
      "      recall: [1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1]\n",
      "      avg_precision: 0.0066\n",
      "      avg_recall: 0.6600\n",
      "  chunk_note_duration_changed:\n",
      "    1:\n",
      "      precision: [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "      recall: [0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0]\n",
      "      avg_precision: 0.3100\n",
      "      avg_recall: 0.3100\n",
      "    3:\n",
      "      precision: [0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0]\n",
      "      recall: [1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0]\n",
      "      avg_precision: 0.1400\n",
      "      avg_recall: 0.4200\n",
      "    5:\n",
      "      precision: [0.2, 0.2, 0.0, 0.2, 0.2, 0.0, 0.0, 0.2, 0.0, 0.2, 0.0, 0.0, 0.0, 0.2, 0.2, 0.0, 0.2, 0.0, 0.2, 0.2, 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.2, 0.2, 0.2, 0.2, 0.0, 0.2, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.0, 0.2, 0.2, 0.2, 0.0, 0.0, 0.2, 0.2, 0.0, 0.0, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.2, 0.2, 0.0, 0.0, 0.2, 0.0, 0.2]\n",
      "      recall: [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1]\n",
      "      avg_precision: 0.0920\n",
      "      avg_recall: 0.4600\n",
      "    10:\n",
      "      precision: [0.1, 0.1, 0.0, 0.1, 0.1, 0.0, 0.0, 0.1, 0.0, 0.1, 0.0, 0.1, 0.0, 0.1, 0.1, 0.0, 0.1, 0.0, 0.1, 0.1, 0.0, 0.1, 0.1, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.0, 0.1, 0.0, 0.1, 0.1, 0.0, 0.0, 0.1, 0.0, 0.1, 0.1, 0.1, 0.1, 0.0, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.1, 0.1, 0.1, 0.0, 0.1, 0.1, 0.1, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.1, 0.1, 0.1]\n",
      "      recall: [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "      avg_precision: 0.0620\n",
      "      avg_recall: 0.6200\n",
      "    25:\n",
      "      precision: [0.04, 0.04, 0.0, 0.04, 0.04, 0.04, 0.0, 0.04, 0.0, 0.04, 0.0, 0.04, 0.0, 0.04, 0.04, 0.0, 0.04, 0.0, 0.04, 0.04, 0.04, 0.04, 0.04, 0.0, 0.0, 0.0, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.0, 0.04, 0.0, 0.04, 0.04, 0.0, 0.04, 0.04, 0.04, 0.04, 0.04, 0.0, 0.04, 0.04, 0.04, 0.04, 0.0, 0.0, 0.04, 0.0, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.0, 0.04, 0.04, 0.04, 0.0, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.0, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.0, 0.0, 0.04, 0.04, 0.04, 0.0, 0.0, 0.04, 0.04, 0.04, 0.04, 0.04, 0.0, 0.04, 0.04, 0.04]\n",
      "      recall: [1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "      avg_precision: 0.0300\n",
      "      avg_recall: 0.7500\n",
      "    50:\n",
      "      precision: [0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.0, 0.02, 0.02, 0.02, 0.0, 0.02, 0.02, 0.02, 0.02, 0.0, 0.02, 0.0, 0.02, 0.02, 0.02, 0.02, 0.02, 0.0, 0.02, 0.0, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.0, 0.02, 0.0, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.0, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.0, 0.02, 0.02, 0.02, 0.0, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.0, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.0, 0.02, 0.02, 0.02, 0.0, 0.0, 0.02, 0.02, 0.02, 0.02, 0.02, 0.0, 0.02, 0.02, 0.02]\n",
      "      recall: [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "      avg_precision: 0.0168\n",
      "      avg_recall: 0.8400\n",
      "    100:\n",
      "      precision: [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.0, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.01, 0.01, 0.01]\n",
      "      recall: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "      avg_precision: 0.0093\n",
      "      avg_recall: 0.9300\n",
      "  chunk_note_deleted:\n",
      "    1:\n",
      "      precision: [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "      recall: [0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n",
      "      avg_precision: 0.2700\n",
      "      avg_recall: 0.2700\n",
      "    3:\n",
      "      precision: [0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333]\n",
      "      recall: [0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1]\n",
      "      avg_precision: 0.1100\n",
      "      avg_recall: 0.3300\n",
      "    5:\n",
      "      precision: [0.2, 0.2, 0.0, 0.2, 0.0, 0.0, 0.0, 0.2, 0.0, 0.2, 0.0, 0.0, 0.0, 0.2, 0.2, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.2, 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.2, 0.2, 0.2, 0.0, 0.0, 0.2, 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.2, 0.2, 0.2, 0.0, 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.2, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.2]\n",
      "      recall: [1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1]\n",
      "      avg_precision: 0.0760\n",
      "      avg_recall: 0.3800\n",
      "    10:\n",
      "      precision: [0.1, 0.1, 0.0, 0.1, 0.0, 0.1, 0.0, 0.1, 0.0, 0.1, 0.0, 0.1, 0.0, 0.1, 0.1, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.1, 0.0, 0.1, 0.1, 0.1, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.1, 0.1, 0.1, 0.0, 0.0, 0.1, 0.0, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.1, 0.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.1, 0.1, 0.0, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.1, 0.1, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.1, 0.1, 0.1]\n",
      "      recall: [1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1]\n",
      "      avg_precision: 0.0500\n",
      "      avg_recall: 0.5000\n",
      "    25:\n",
      "      precision: [0.04, 0.04, 0.0, 0.04, 0.0, 0.04, 0.0, 0.04, 0.0, 0.04, 0.0, 0.04, 0.04, 0.04, 0.04, 0.0, 0.04, 0.0, 0.04, 0.04, 0.0, 0.04, 0.04, 0.0, 0.04, 0.0, 0.04, 0.04, 0.04, 0.0, 0.04, 0.04, 0.04, 0.0, 0.0, 0.0, 0.04, 0.04, 0.0, 0.04, 0.04, 0.04, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04, 0.0, 0.0, 0.04, 0.0, 0.04, 0.04, 0.04, 0.0, 0.0, 0.04, 0.0, 0.04, 0.04, 0.0, 0.0, 0.0, 0.0, 0.04, 0.0, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.0, 0.0, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.0, 0.0, 0.04, 0.04, 0.04, 0.04, 0.0, 0.0, 0.04, 0.0, 0.04, 0.0, 0.0, 0.04, 0.04, 0.04]\n",
      "      recall: [1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1]\n",
      "      avg_precision: 0.0240\n",
      "      avg_recall: 0.6000\n",
      "    50:\n",
      "      precision: [0.02, 0.02, 0.0, 0.02, 0.0, 0.02, 0.0, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.0, 0.02, 0.0, 0.02, 0.02, 0.0, 0.02, 0.02, 0.0, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.0, 0.0, 0.0, 0.02, 0.02, 0.0, 0.02, 0.02, 0.02, 0.02, 0.02, 0.0, 0.02, 0.0, 0.02, 0.02, 0.0, 0.0, 0.02, 0.0, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.0, 0.02, 0.02, 0.0, 0.0, 0.0, 0.0, 0.02, 0.0, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.0, 0.0, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.0, 0.02, 0.02, 0.02, 0.02, 0.0, 0.02, 0.02, 0.0, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02]\n",
      "      recall: [1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "      avg_precision: 0.0146\n",
      "      avg_recall: 0.7300\n",
      "    100:\n",
      "      precision: [0.01, 0.01, 0.01, 0.01, 0.0, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.01, 0.0, 0.01, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.0, 0.01, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n",
      "      recall: [1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "      avg_precision: 0.0082\n",
      "      avg_recall: 0.8200\n",
      "  chunk_note_inserted:\n",
      "    1:\n",
      "      precision: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "      recall: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "      avg_precision: 0.1900\n",
      "      avg_recall: 0.1900\n",
      "    3:\n",
      "      precision: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0]\n",
      "      recall: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0]\n",
      "      avg_precision: 0.1000\n",
      "      avg_recall: 0.3000\n",
      "    5:\n",
      "      precision: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.0, 0.2, 0.0, 0.2, 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.2, 0.2, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.2, 0.0, 0.2, 0.2, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.2, 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.0]\n",
      "      recall: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0]\n",
      "      avg_precision: 0.0600\n",
      "      avg_recall: 0.3000\n",
      "    10:\n",
      "      precision: [0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.1, 0.0, 0.1, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.1, 0.0, 0.1, 0.0, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.1, 0.0, 0.1, 0.1, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.1, 0.0, 0.1, 0.1, 0.0, 0.1, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.1, 0.0, 0.1, 0.0, 0.1, 0.0, 0.0, 0.1, 0.0, 0.1, 0.0, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.1, 0.0, 0.0, 0.1, 0.0, 0.0, 0.1, 0.1, 0.0]\n",
      "      recall: [0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0]\n",
      "      avg_precision: 0.0370\n",
      "      avg_recall: 0.3700\n",
      "    25:\n",
      "      precision: [0.0, 0.04, 0.0, 0.0, 0.0, 0.04, 0.0, 0.04, 0.0, 0.04, 0.0, 0.0, 0.04, 0.04, 0.04, 0.0, 0.04, 0.0, 0.04, 0.04, 0.04, 0.04, 0.0, 0.0, 0.0, 0.0, 0.04, 0.04, 0.0, 0.04, 0.0, 0.04, 0.04, 0.0, 0.0, 0.04, 0.04, 0.04, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04, 0.0, 0.0, 0.0, 0.04, 0.0, 0.04, 0.04, 0.0, 0.04, 0.04, 0.0, 0.0, 0.04, 0.04, 0.04, 0.0, 0.0, 0.04, 0.0, 0.0, 0.04, 0.04, 0.04, 0.0, 0.04, 0.0, 0.04, 0.0, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.0, 0.0, 0.0, 0.0, 0.04, 0.04, 0.04, 0.04, 0.0, 0.0, 0.04, 0.0, 0.0, 0.04, 0.04, 0.0]\n",
      "      recall: [0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0]\n",
      "      avg_precision: 0.0204\n",
      "      avg_recall: 0.5100\n",
      "    50:\n",
      "      precision: [0.0, 0.02, 0.0, 0.0, 0.0, 0.02, 0.0, 0.02, 0.0, 0.02, 0.0, 0.0, 0.02, 0.02, 0.02, 0.0, 0.02, 0.0, 0.02, 0.02, 0.02, 0.02, 0.0, 0.0, 0.0, 0.0, 0.02, 0.02, 0.0, 0.02, 0.0, 0.02, 0.02, 0.0, 0.0, 0.02, 0.02, 0.02, 0.0, 0.02, 0.0, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02, 0.0, 0.0, 0.0, 0.02, 0.0, 0.02, 0.02, 0.0, 0.02, 0.02, 0.0, 0.02, 0.02, 0.02, 0.02, 0.0, 0.0, 0.02, 0.0, 0.0, 0.02, 0.02, 0.02, 0.0, 0.02, 0.0, 0.02, 0.0, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.0, 0.0, 0.0, 0.02, 0.02, 0.02, 0.02, 0.0, 0.02, 0.02, 0.0, 0.0, 0.02, 0.02, 0.0]\n",
      "      recall: [0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0]\n",
      "      avg_precision: 0.0110\n",
      "      avg_recall: 0.5500\n",
      "    100:\n",
      "      precision: [0.0, 0.01, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.0, 0.01, 0.01, 0.0, 0.01, 0.01, 0.01, 0.0, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.0, 0.0, 0.01, 0.0, 0.01, 0.01, 0.0, 0.01, 0.0, 0.01, 0.01, 0.0, 0.0, 0.01, 0.01, 0.01, 0.0, 0.01, 0.0, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.0, 0.01, 0.0, 0.0, 0.01, 0.01, 0.01, 0.0, 0.01, 0.0, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.0, 0.01, 0.01, 0.01, 0.0, 0.01, 0.01, 0.0]\n",
      "      recall: [0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0]\n",
      "      avg_precision: 0.0063\n",
      "      avg_recall: 0.6300\n"
     ]
    }
   ],
   "source": [
    "def print_nested_dict(d, indent=0):\n",
    "    for key, value in d.items():\n",
    "        print('  ' * indent + str(key) + ':', end='')\n",
    "        if isinstance(value, dict):\n",
    "            print()\n",
    "            print_nested_dict(value, indent+1)\n",
    "        else:\n",
    "            if isinstance(value, float):\n",
    "                print(f\" {value:.4f}\")\n",
    "            else:\n",
    "                print(f\" {value}\")\n",
    "\n",
    "# Usage\n",
    "print_nested_dict(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
